<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>hive | David W. Streever</title>
    <link>http://www.streever.com/tags/hive/</link>
      <atom:link href="http://www.streever.com/tags/hive/index.xml" rel="self" type="application/rss+xml" />
    <description>hive</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><copyright>Â© 2019</copyright><lastBuildDate>Thu, 24 Oct 2019 00:00:00 +0000</lastBuildDate>
    <image>
      <url>http://www.streever.com/img/icon-192.png</url>
      <title>hive</title>
      <link>http://www.streever.com/tags/hive/</link>
    </image>
    
    <item>
      <title>&#39;Right Pathing&#39; Alternate Workloads while using HiveServer2 Interactive (LLAP)</title>
      <link>http://www.streever.com/post/2019/drafts/container_mode_in_llap/</link>
      <pubDate>Thu, 24 Oct 2019 00:00:00 +0000</pubDate>
      <guid>http://www.streever.com/post/2019/drafts/container_mode_in_llap/</guid>
      <description>

&lt;blockquote&gt;
&lt;p&gt;A few assumptions:  HDP 3.1.4 and Ambari have been used to work through these scenarios.  If you&amp;rsquo;re running different versions, additional tweaks may be required.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Hive LLAP is a great way to speed up analytical queries.  The caching layer and immediate task allocation model provides performance that is competitive and often faster than other traditional EDW solutions.&lt;/p&gt;

&lt;p&gt;LLAP&amp;rsquo;s caching layer uses an LFRU (Less Frequently Recently Used) eviction model to manage it&amp;rsquo;s caching layer.  The caching layer is shared across user sessions in LLAP, which means data cached by one user/session is available to another user/session.  The caching model is a significant advantage over session-scoped caches you&amp;rsquo;ll get with other big data query engines.&lt;/p&gt;

&lt;p&gt;From a practical standpoint, LLAP is best suited for BI, discovery, and dashboard-type queries.  These queries share common datasets and need to respond quickly because there is usually a user waiting on the other end.&lt;/p&gt;

&lt;p&gt;While perfectly capable, using LLAP for ETL/ELT isn&amp;rsquo;t the best use of this elevated resource.  Moving massive amounts of data through LLAP doing ELT/ELT work has a few effects:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Fills cache with datasets that aren&amp;rsquo;t benefiting anyone downstream.&lt;/li&gt;
&lt;li&gt;Forces eviction of cached elements that &amp;lsquo;are&amp;rsquo; benefiting other users.&lt;/li&gt;
&lt;li&gt;Consumes resources used by a community with stricter SLA&amp;rsquo;s, when the ETL/ELT community has different SLA standards.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;problem&#34;&gt;Problem&lt;/h2&gt;

&lt;p&gt;So what can you do when your attached to HS2i and want to run an ETL/ELT job, which is a long-running job that doesn&amp;rsquo;t require the resources of LLAP, or you want to be a courteous user and leave some of those LLAP resources for someone else?  It would be perfectly fine to run your query in the traditional HS2 environment, but you can&amp;rsquo;t/don&amp;rsquo;t want to connect to another environment just to run the query.&lt;/p&gt;

&lt;h2 id=&#34;solution&#34;&gt;Solution&lt;/h2&gt;

&lt;p&gt;Well, HS2i can launch jobs into containers instead of the default &amp;lsquo;llap&amp;rsquo; environment.  Therefore, saving LLAP resources and &amp;lsquo;right pathing&amp;rsquo; your workload.&lt;/p&gt;

&lt;p&gt;HS2i can be configurated to allow sessions to override the &amp;lsquo;execution mode&amp;rsquo; of a query.  &lt;em&gt;When a session is created, and a query is run, the execution mode can not be changed.  Another session must be created.&lt;/em&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;hive.execution.mode
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This setting is found in several places (in Ambari) and is used by a &amp;lsquo;session&amp;rsquo; to determine where a query will be executed.  Options are:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;container&lt;/li&gt;
&lt;li&gt;llap&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;As with all settings we&amp;rsquo;ll mention in this article, make sure you are reviewing/setting the values that are appropriate for the environment your in.  For example: In Ambari and LLAP, see the &amp;lsquo;hive-interactive-*&amp;rsquo; sections.&lt;/p&gt;

&lt;p&gt;The &lt;code&gt;hive.execution.mode&lt;/code&gt; setting is set and defaults to the appropriate mode for the environment.  Meaning, &amp;lsquo;container&amp;rsquo; is set for the &amp;lsquo;HS2&amp;rsquo; environment, and &amp;lsquo;llap&amp;rsquo; is set for the &amp;lsquo;HS2i&amp;rsquo; environment.  We do NOT want to make this change at the environment level.  &lt;em&gt;We will only change this at the session level.&lt;/em&gt;&lt;/p&gt;

&lt;h2 id=&#34;some-caveats&#34;&gt;Some Caveats&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;&lt;em&gt;With&lt;/em&gt;&lt;/strong&gt; Workload Management Enabled&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;You can &lt;em&gt;NOT&lt;/em&gt; request an alternate YARN queue to run.  All &amp;lsquo;container&amp;rsquo; execution mode queries will run in the &amp;lsquo;Workload&amp;rsquo; queue defined by &lt;code&gt;hive.server2.tez.interactive.queue&lt;/code&gt;.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;&lt;em&gt;Without&lt;/em&gt;&lt;/strong&gt; Workload Management Enabled&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;You &lt;em&gt;CAN&lt;/em&gt; request an alternate YARN queue to run &amp;lsquo;container&amp;rsquo; mode requests in.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&#34;controls&#34;&gt;Controls&lt;/h2&gt;

&lt;h3 id=&#34;session-level-settings&#34;&gt;Session Level Settings&lt;/h3&gt;

&lt;p&gt;After adjusting a few environment settings to allow an &amp;lsquo;alternate&amp;rsquo; execution mode, the execution path is controlled by the session.  Users wanting to use the &amp;lsquo;alternate&amp;rsquo; path will declare the alternate path before launching the job.  If nothing is specified, jobs will run in LLAP.  As I mentioned before, once a query has been run in a session, the execution mode for that session can &lt;strong&gt;NOT&lt;/strong&gt; be changed.  Doing so will result in an error.  A new session is required, if they wish the change the &lt;code&gt;execution mode&lt;/code&gt;.&lt;/p&gt;

&lt;h3 id=&#34;environment-level-settings-defaults&#34;&gt;Environment Level Settings (Defaults)&lt;/h3&gt;

&lt;p&gt;Note the sections for each of these settings.  Ambari has the same settings in many areas to control different deployments of Hive Server2.&lt;/p&gt;

&lt;h5 id=&#34;llap-daemon-and-concurrency-settings-default&#34;&gt;LLAP Daemon and Concurrency Settings (Default)&lt;/h5&gt;

&lt;p&gt;&lt;img src=&#34;./queue_n_concurrency.png&#34; alt=&#34;LLAP Daemon and Concurrency Settings&#34; /&gt;&lt;/p&gt;

&lt;p&gt;What&amp;rsquo;s interesting is that the default configuration runs the LLAP daemons AND the concurrency AM in the same queue.  But this isn&amp;rsquo;t necessary, as we&amp;rsquo;ll see later.&lt;/p&gt;

&lt;h6 id=&#34;llap-execution-restrictions-default&#34;&gt;LLAP Execution Restrictions (Default)&lt;/h6&gt;

&lt;p&gt;&lt;img src=&#34;./hs2i_restricted.png&#34; alt=&#34;LLAP Execution Restrictions&#34; /&gt;&lt;/p&gt;

&lt;p&gt;We&amp;rsquo;ll change this restriction to allow users to set the &lt;code&gt;hive.exection.mode&lt;/code&gt; later in the options section.&lt;/p&gt;

&lt;h6 id=&#34;llap-interactive-queue&#34;&gt;LLAP Interactive Queue&lt;/h6&gt;

&lt;p&gt;&lt;img src=&#34;./llap_interactive_queue.png&#34; alt=&#34;LLAP Interactive Queue&#34; /&gt;&lt;/p&gt;

&lt;p&gt;The &amp;lsquo;interactive&amp;rsquo; setting needs to be set to enable &lt;strong&gt;Workload Management&lt;/strong&gt;.  The Workload Management AM will run in the defined queue.  These AM&amp;rsquo;s represent each concurrent query (capability) for LLAP.  That concurrency is defined by the aggregate of the &lt;code&gt;parallelism&lt;/code&gt; configured for Workload Management. See this &lt;a href=&#34;https://github.com/dstreev/big-data-apps/blob/master/apps/llap_workload/r1_plan_create.sql&#34; target=&#34;_blank&#34;&gt;example script&lt;/a&gt; as a guide for starting Workload Management. It is not controlled via the concurrency settings we&amp;rsquo;ve seen before (&lt;code&gt;hive.server2.tez.sessions.per.default.queue&lt;/code&gt;).&lt;/p&gt;

&lt;h3 id=&#34;environment-level-setting-changes&#34;&gt;Environment Level Setting Changes&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Remove the &lt;code&gt;hive.execution.mode&lt;/code&gt; value from &amp;ldquo;Restricted session configs&amp;rdquo; (&lt;code&gt;hive.server2.tez.sessions.restricted.configs&lt;/code&gt;)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&#34;./exec_mode_restriction_removed.png&#34; alt=&#34;Removed&#34; /&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Allow Custom Queues by changing &lt;code&gt;ignore&lt;/code&gt; to &lt;code&gt;true&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;hive.server2.tez.sessions.custom.queue.allowed=true
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&#34;./allow_custom_queue.png&#34; alt=&#34;Custom Allowed&#34; /&gt;&lt;/p&gt;

&lt;h5 id=&#34;optional-environment-setting-tweaks-queues&#34;&gt;Optional Environment Setting Tweaks (Queues)&lt;/h5&gt;

&lt;p&gt;These settings have more to do with where you want parts of the system to run (which queues).&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;code&gt;hive.server2.tez.default.queues&lt;/code&gt; controls where the Concurrency AM&amp;rsquo;s will run when Workload Management is &lt;em&gt;NOT&lt;/em&gt; enabled.&lt;/p&gt;

&lt;p&gt;&lt;code&gt;hive.llap.daemon.queue.name&lt;/code&gt; controls where the LLAP environment will run.&lt;/p&gt;

&lt;p&gt;&lt;code&gt;hive.server2.tez.interactive.queue&lt;/code&gt; controls where the Workload Management AM&amp;rsquo;s will run, when Workload Management is activated.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&#34;options&#34;&gt;Options&lt;/h2&gt;

&lt;p&gt;The behavior changes a bit, depending on whether you&amp;rsquo;re using Workload Management or not.  My suggestion is to &lt;em&gt;NOT&lt;/em&gt; enable Workload Management at first to see what lands in which queue.  Once you activate Workload Management, you will &lt;em&gt;NOT&lt;/em&gt; be able to launch jobs in &lt;code&gt;container&lt;/code&gt; mode outside the queue setup in &lt;code&gt;hive.server2.tez.interactive.queue&lt;/code&gt; .&lt;/p&gt;

&lt;h5 id=&#34;option-1-without-workload-management&#34;&gt;Option #1 - Without Workload Management&lt;/h5&gt;

&lt;p&gt;Scenario: &lt;em&gt;Run LLAP and Concurrency AM&amp;rsquo;s in the same queue&lt;/em&gt;.  Allow users to specify an alternate queue to run &lt;code&gt;container&lt;/code&gt; mode jobs.&lt;/p&gt;

&lt;p&gt;When jobs are launched in &lt;code&gt;container&lt;/code&gt; execution mode, YARN will allocate task resources alongside the AM controlling the &amp;lsquo;DAG.&amp;rsquo;  So where ever you launch the AM for the job, that queue will need resources to run the job.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Environment&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;hive.server2.tez.sessions.restricted.configs=hive.execution.engine
hive.server2.tez.sessions.custom.queue.allowed=true
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Unset (To disable Workload Management)&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;hive.server2.tez.interactive.queue
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;Session Level&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Set via Hive/Beeline Init, Script, or JDBC connection string.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;set hive.execution.mode=container
set tez.queue.name=&amp;lt;target_queue&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Launch the query and check the Resource Manager.  You should see the AM in the target queue, and that application in YARN will grow additional containers to run the job.&lt;/p&gt;

&lt;h5 id=&#34;option-2-without-workload-management&#34;&gt;Option #2 - Without Workload Management&lt;/h5&gt;

&lt;p&gt;Scenario: &lt;em&gt;Run LLAP and Concurrency AM&amp;rsquo;s in different queues&lt;/em&gt;.  Allow users to specify an alternate queue to run &lt;code&gt;container&lt;/code&gt; mode jobs.&lt;/p&gt;

&lt;p&gt;When jobs are launched in &lt;code&gt;container&lt;/code&gt; execution mode, YARN will allocate task resources alongside the AM controlling the &amp;lsquo;DAG.&amp;rsquo;  So where ever you launch the AM for the job, that queue will need resources to run the job.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Environment&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;hive.server2.tez.sessions.restricted.configs=hive.execution.engine
hive.server2.tez.sessions.custom.queue.allowed=true
hive.server2.tez.default.queues=llap_tez_am
hive.llap.daemon.queue.name=llap
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Unset (To disable Workload Management)&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;hive.server2.tez.interactive.queue
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;Session Level&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Set via Hive/Beeline Init, Script, or JDBC connection string.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;set hive.execution.mode=container
set tez.queue.name=&amp;lt;target_queue&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Launch the query and check the Resource Manager.  You should see the AM in the target queue, and that AM in YARN will grow additional containers to run the job.&lt;/p&gt;

&lt;h5 id=&#34;option-3-with-workload-management&#34;&gt;Option #3 - With Workload Management&lt;/h5&gt;

&lt;p&gt;Scenario: LLAP and Workload Management AM in different queues.  Users will &lt;em&gt;NOT&lt;/em&gt; be able to specify an alternate queue.  The Workload Management AM will grow to fulfill the DAG request.  The YARN queue &lt;code&gt;hive.server2.tez.interactive.queue&lt;/code&gt; will need to be large enough to contain the other Workload Management AM&amp;rsquo;s in addition to the job requirements.  If the queue is small and the other Workload AM&amp;rsquo;s have not been allocated or reclaimed during a quiet period, new jobs may not launch right away.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Environment&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;hive.server2.tez.sessions.restricted.configs=hive.execution.engine
hive.server2.tez.sessions.custom.queue.allowed=true
-- Utilitization of &#39;llap_tez_am&#39; should be nil with Workload Management
hive.server2.tez.default.queues=llap_tez_am
hive.llap.daemon.queue.name=llap
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Set (To enable Workload Management).  There&amp;rsquo;s more to do for Workload Management, which isn&amp;rsquo;t covered here.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;hive.server2.tez.interactive.queue=llap_wm
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;Session Level&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Set via Hive/Beeline Init, Script, or JDBC connection string.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;set hive.execution.mode=container
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Launch the query and check the Resource Manager.  You should see the AM in the target queue (llap_wm), and that AM in YARN will grow additional containers to run the job.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Filter Hive Compactions</title>
      <link>http://www.streever.com/post/2019/filter-hive-compactions/</link>
      <pubDate>Tue, 15 Oct 2019 00:00:00 +0000</pubDate>
      <guid>http://www.streever.com/post/2019/filter-hive-compactions/</guid>
      <description>

&lt;p&gt;From Beeline or a standard JDBC client connected to Hive, compactions can be seen with the standard SQL:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;SHOW COMPACTIONS;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;But this method has a couple of problems:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;No Filtering&lt;/li&gt;
&lt;li&gt;Timestamps are hard to interpret&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Until additional functionality is available for this built in function, we can do the following.&lt;/p&gt;

&lt;p&gt;Add links to the Metastore DB tables and create custom views to review compaction details.  See &lt;a href=&#34;http://www.streever.com/post/the-power-of-hive-jdbc-federation&#34;&gt;The Power of Hive JDBC Federation&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;build-out-metadata-elements&#34;&gt;Build Out Metadata Elements&lt;/h2&gt;

&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    &lt;p&gt;A word of caution here.  All the &amp;lsquo;extras&amp;rsquo; you create against the metastore DB can/may break with the next release.  This isn&amp;rsquo;t a supported method of accessing metadata.&lt;/p&gt;

&lt;p&gt;Don&amp;rsquo;t add &lt;em&gt;new&lt;/em&gt; tables to the current &lt;code&gt;sys.db&lt;/code&gt;.  That&amp;rsquo;s bad form and could cause issues for the platform during the next upgrade cycle, especially if there are naming conflicts.  Put it somewhere else!!&lt;/p&gt;

  &lt;/div&gt;
&lt;/div&gt;

&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;CREATE DATABASE IF NOT EXISTS custom_sys;

DROP TABLE IF EXISTS `custom_sys`.`completed_compactions`;
DROP TABLE IF EXISTS `custom_sys`.`compaction_queue`;

CREATE EXTERNAL TABLE `custom_sys`.`completed_compactions`(
	CC_ID bigint COMMENT &#39;from deserializer&#39;,
	CC_DATABASE string COMMENT &#39;from deserializer&#39;,
	CC_TABLE string COMMENT &#39;from deserializer&#39;,
	CC_PARTITION string COMMENT &#39;from deserializer&#39;,
	CC_STATE string COMMENT &#39;from deserializer&#39;,
	CC_TYPE string COMMENT &#39;from deserializer&#39;,
	CC_TBLPROPERTIES string COMMENT &#39;from deserializer&#39;,
	CC_WORKER_ID string COMMENT &#39;from deserializer&#39;,
	CC_START bigint COMMENT &#39;from deserializer&#39;,
	CC_END bigint COMMENT &#39;from deserializer&#39;,
	CC_RUN_AS string COMMENT &#39;from deserializer&#39;,
	CC_HIGHEST_WRITE_ID bigint COMMENT &#39;from deserializer&#39;,
	CC_META_INFO string COMMENT &#39;from deserializer&#39;,
	CC_HADOOP_JOB_ID string COMMENT &#39;from deserializer&#39;
)
 ROW FORMAT SERDE                                   
   &#39;org.apache.hive.storage.jdbc.JdbcSerDe&#39;         
 STORED BY                                          
   &#39;org.apache.hive.storage.jdbc.JdbcStorageHandler&#39;  
 WITH SERDEPROPERTIES (                             
   &#39;serialization.format&#39;=&#39;1&#39;)                      
 TBLPROPERTIES (                                    
   &#39;bucketing_version&#39;=&#39;2&#39;,                         
   &#39;hive.sql.database.type&#39;=&#39;METASTORE&#39;,            
   &#39;hive.sql.query&#39;=&#39;SELECT CC_ID, CC_DATABASE, CC_TABLE, CC_PARTITION, CC_STATE, CC_TYPE, CC_TBLPROPERTIES, CC_WORKER_ID, CC_START, CC_END, CC_RUN_AS, CC_HIGHEST_WRITE_ID, CC_META_INFO, CC_HADOOP_JOB_ID FROM COMPLETED_COMPACTIONS&#39;);

CREATE EXTERNAL TABLE `custom_sys`.`compaction_queue`(
	CQ_ID bigint COMMENT &#39;from deserializer&#39;,
	CQ_DATABASE string COMMENT &#39;from deserializer&#39;,
	CQ_TABLE string COMMENT &#39;from deserializer&#39;,
	CQ_PARTITION string COMMENT &#39;from deserializer&#39;,
	CQ_STATE string COMMENT &#39;from deserializer&#39;,
	CQ_TYPE string COMMENT &#39;from deserializer&#39;,
	CQ_TBLPROPERTIES string COMMENT &#39;from deserializer&#39;,
	CQ_WORKER_ID string COMMENT &#39;from deserializer&#39;,
	CQ_START bigint COMMENT &#39;from deserializer&#39;,
	CQ_RUN_AS string COMMENT &#39;from deserializer&#39;,
	CQ_HIGHEST_WRITE_ID bigint COMMENT &#39;from deserializer&#39;,
	CQ_META_INFO string COMMENT &#39;from deserializer&#39;,
	CQ_HADOOP_JOB_ID string COMMENT &#39;from deserializer&#39;
)
 ROW FORMAT SERDE                                   
   &#39;org.apache.hive.storage.jdbc.JdbcSerDe&#39;         
 STORED BY                                          
   &#39;org.apache.hive.storage.jdbc.JdbcStorageHandler&#39;  
 WITH SERDEPROPERTIES (                             
   &#39;serialization.format&#39;=&#39;1&#39;)                      
 TBLPROPERTIES (                                    
   &#39;bucketing_version&#39;=&#39;2&#39;,                         
   &#39;hive.sql.database.type&#39;=&#39;METASTORE&#39;,            
   &#39;hive.sql.query&#39;=&#39;SELECT CQ_ID, CQ_DATABASE, CQ_TABLE, CQ_PARTITION, CQ_STATE, CQ_TYPE, CQ_TBLPROPERTIES, CQ_WORKER_ID, CQ_START, CQ_RUN_AS, CQ_HIGHEST_WRITE_ID, CQ_META_INFO, CQ_HADOOP_JOB_ID FROM COMPACTION_QUEUE&#39;);

DROP VIEW IF EXISTS `custom_sys`.`compactions`;

-- TODO: Handle / Show Aborted Transactions (maybe) I think txn data may be transient...
CREATE VIEW IF NOT EXISTS `custom_sys`.`compactions` AS
SELECT CC_ID AS id,
       CC_DATABASE AS `database`,
       CC_TABLE AS `table`,
       CC_PARTITION AS `partition`,
       CASE CC_STATE
           WHEN &#39;s&#39; THEN &#39;SUCCEEDED&#39;
           WHEN &#39;a&#39; THEN &#39;ATTEMPTED&#39;
           WHEN &#39;f&#39; THEN &#39;FAILED&#39;
       END AS STATE,
       CASE CC_TYPE
           WHEN &#39;a&#39; THEN &#39;MAJOR&#39;
           WHEN &#39;i&#39; THEN &#39;MINOR&#39;
       END AS TYPE,
       CC_TBLPROPERTIES AS tblproperties,
       CC_WORKER_ID AS worker_id,
       to_utc_timestamp(CC_START,&#39;UTC&#39;) AS `start`,
       to_utc_timestamp(CC_END, &#39;UTC&#39;) AS `end`,
       CC_RUN_AS AS run_as,
       CC_HIGHEST_WRITE_ID AS highest_write_id,
       CC_META_INFO AS meta_info,
       CC_HADOOP_JOB_ID AS hadoop_job_id
FROM `custom_sys`.`completed_compactions`
UNION ALL
SELECT CQ_ID AS id,
       CQ_DATABASE AS `database`,
       CQ_TABLE AS `table`,
       CQ_PARTITION AS `partition`,
       CASE CQ_STATE
           WHEN &#39;i&#39; THEN &#39;INITIATED&#39;
           WHEN &#39;w&#39; THEN &#39;WORKING&#39;
           WHEN &#39;r&#39; THEN &#39;READY_FOR_CLEANING&#39;
       END AS `state`,
       CASE CQ_TYPE
           WHEN &#39;a&#39; THEN &#39;MAJOR&#39;
           WHEN &#39;i&#39; THEN &#39;MINOR&#39;
       END AS `type`,
       CQ_TBLPROPERTIES AS tblproperties,
       CQ_WORKER_ID AS worker_id,
       to_utc_timestamp(CQ_START, &#39;UTC&#39;) AS `start`,
       NULL AS `end`,
               CQ_RUN_AS AS run_as,
               CQ_HIGHEST_WRITE_ID AS highest_write_id,
               CQ_META_INFO AS meta_info,
               CQ_HADOOP_JOB_ID AS hadoop_job_id
FROM `custom_sys`.`compaction_queue`;

&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;see-the-last-10-compaction-events&#34;&gt;See the last 10 compaction events&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;select 
	`database`, `table`, `partition`, `state`, `type`, `start`, `end`, hadoop_job_id 
FROM
	`custom_sys`.`compactions` 
ORDER BY `start` DESC 
LIMIT 10;
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;show-the-last-10-failed-compaction-event&#34;&gt;Show the last 10 failed compaction event&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;-- `state` options are &#39;SUCCEEDED&#39;, &#39;ATTEMPTED&#39;, &#39;FAILED&#39;, &#39;INITIATED&#39;, &#39;WORKING&#39;, and &#39;READY_FOR_CLEANING&#39;
-- `type` options are &#39;MAJOR&#39; and &#39;MINOR&#39;
select 
`database`, `table`, `partition`, `state`, `type`, `start`, `end` 
FROM
	`custom_sys`.`compactions` 
WHERE `state` = &#39;FAILED&#39; 
ORDER BY `start` DESC 
LIMIT 10;
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>HDP3 Upgrade Planning</title>
      <link>http://www.streever.com/project/hdp3-upgrade-planning/</link>
      <pubDate>Tue, 15 Oct 2019 00:00:00 +0000</pubDate>
      <guid>http://www.streever.com/project/hdp3-upgrade-planning/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Hive LLAP Calculator</title>
      <link>http://www.streever.com/project/hive-llap-calculator/</link>
      <pubDate>Tue, 15 Oct 2019 00:00:00 +0000</pubDate>
      <guid>http://www.streever.com/project/hive-llap-calculator/</guid>
      <description></description>
    </item>
    
    <item>
      <title>The Power of Hive JDBC Federation</title>
      <link>http://www.streever.com/post/2019/jdbc-federation/</link>
      <pubDate>Tue, 15 Oct 2019 00:00:00 +0000</pubDate>
      <guid>http://www.streever.com/post/2019/jdbc-federation/</guid>
      <description>

&lt;p&gt;Hive jdbc-federation is a powerful mechanism to include external sources in your hive ecosystem.   Apache Software Foundation has excellent docs detailing this feature referred to as the &lt;a href=&#34;https://cwiki.apache.org/confluence/display/Hive/JdbcStorageHandler&#34; target=&#34;_blank&#34;&gt;JDBCStorageHandler&lt;/a&gt; .&lt;/p&gt;

&lt;p&gt;Interesting points about this StorageHandler include:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Securing Passwords - &lt;strong&gt;Protects  passwords using a &amp;lsquo;jceks&amp;rsquo; file stored on &amp;lsquo;hdfs&amp;rsquo;&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Partitioning - &lt;strong&gt;Could be used as an alternate to SQOOP for importing data to Hive&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;more-hive-metadata&#34;&gt;More Hive Metadata!&lt;/h2&gt;

&lt;p&gt;Hive Metadata, previously only available via &lt;code&gt;WebHCat&lt;/code&gt; which has been removed, can be retrieved through hive&amp;rsquo;s &lt;code&gt;sys&lt;/code&gt; database.   And the &lt;code&gt;sys&lt;/code&gt; db is actually using the JDBCStorageHandler with a special tblproperty &lt;code&gt;&#39;hive.sql.database.type&#39;=&#39;METASTORE&#39;&lt;/code&gt; used with the storage handler and &lt;code&gt;&#39;hive.sql.query&#39;=&#39;SELECT ... FROM ...&#39;&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;I&amp;rsquo;ve used this technique to expose tables that support &lt;code&gt;COMPACTION&lt;/code&gt;, &lt;code&gt;LOCKS&lt;/code&gt;, and &lt;code&gt;TRANSACTIONS&lt;/code&gt; in order to fill some gaps with the current admin functions.   See the examples below for details.&lt;/p&gt;

&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    &lt;p&gt;A word of caution here.  All the &amp;lsquo;extras&amp;rsquo; you create against the metastore DB can/may break with the next release.  This isn&amp;rsquo;t a supported method of accessing metadata.&lt;/p&gt;

&lt;p&gt;Don&amp;rsquo;t add &lt;em&gt;new&lt;/em&gt; tables to the current &lt;code&gt;sys.db&lt;/code&gt;.  That&amp;rsquo;s bad form and could cause issues for the platform during the next upgrade cycle, especially if there are naming conflicts.  Put it somewhere else!!&lt;/p&gt;

  &lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Managing Immutable Data in Hive with Windowing RANK</title>
      <link>http://www.streever.com/post/2015/-mng-immutable-data-windowing-style/</link>
      <pubDate>Thu, 27 Aug 2015 00:00:00 +0000</pubDate>
      <guid>http://www.streever.com/post/2015/-mng-immutable-data-windowing-style/</guid>
      <description>

&lt;p&gt;I&amp;rsquo;m often asked how to &amp;ldquo;update&amp;rdquo; records in Hive.  We&amp;rsquo;ll you can&amp;rsquo;t, at least not yet and not in the sense you maybe accustom in an RDBMS.&lt;/p&gt;

&lt;p&gt;Store your record updates in a transactional table that includes some identifier that represents the most resent update.  For example:&lt;/p&gt;

&lt;h3 id=&#34;table-schema&#34;&gt;Table Schema&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;create external table fitness (
    firstname string,
    updated date,
    weight double
)
ROW FORMAT SERDE &#39;org.apache.hadoop.hive.serde2.OpenCSVSerde&#39;
STORED AS TEXTFILE
LOCATION &#39;...&#39;;
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;data&#34;&gt;Data&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;fitness.firstname  fitness.updated  fitness.weight 
-----------------  ---------------  -------------- 
david              2015-01-12       210            
david              2015-04-03       205            
david              2015-06-02       200            
david              2015-08-23       195
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Hive now support &amp;ldquo;Windowing&amp;rdquo; functions which make it really simply to extract the &amp;ldquo;most recent&amp;rdquo; record from this table.  Use those results to build your new &amp;ldquo;entity&amp;rdquo; table.&lt;/p&gt;

&lt;h3 id=&#34;rank-to-find-most-current&#34;&gt;Rank to Find Most Current&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;SELECT
  sub.firstname firstname,
  sub.updated updated,
  sub.weight weight
FROM
  (
    SELECT
      firstname,
      updated,
      weight,
      rank() over(partition BY firstname ORDER BY updated desc) rank
    FROM
      fitness
  ) sub
WHERE
  sub.rank=1;
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;results&#34;&gt;Results&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;firstname  updated     weight 
---------  ----------  ------ 
david      2015-08-23  195     
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
  </channel>
</rss>
