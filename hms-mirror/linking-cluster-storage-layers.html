<!DOCTYPE html SYSTEM "about:legacy-compat">
<html lang="en-US" data-preset="contrast" data-primary-color="#307FFF"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta charset="UTF-8"><meta name="built-on" content="2024-08-15T11:41:21.211656"><title>Linking Cluster Storage Layers | hms-mirror</title><script type="application/json" id="virtual-toc-data">[{"id":"goal","level":0,"title":"Goal","anchor":"#goal"},{"id":"scenario-1","level":0,"title":"Scenario #1","anchor":"#scenario-1"}]</script><script type="application/json" id="topic-shortcuts"></script><link href="https://resources.jetbrains.com/writerside/apidoc/6.10.0-b408/app.css" rel="stylesheet"><meta name="msapplication-TileColor" content="#000000"><link rel="apple-touch-icon" sizes="180x180" href="https://jetbrains.com/apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="https://jetbrains.com/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="https://jetbrains.com/favicon-16x16.png"><meta name="msapplication-TileImage" content="https://resources.jetbrains.com/storage/ui/favicons/mstile-144x144.png"><meta name="msapplication-square70x70logo" content="https://resources.jetbrains.com/storage/ui/favicons/mstile-70x70.png"><meta name="msapplication-square150x150logo" content="https://resources.jetbrains.com/storage/ui/favicons/mstile-150x150.png"><meta name="msapplication-wide310x150logo" content="https://resources.jetbrains.com/storage/ui/favicons/mstile-310x150.png"><meta name="msapplication-square310x310logo" content="https://resources.jetbrains.com/storage/ui/favicons/mstile-310x310.png"><meta name="image" content=""><!-- Open Graph --><meta property="og:title" content="Linking Cluster Storage Layers | hms-mirror"><meta property="og:description" content=""><meta property="og:image" content=""><meta property="og:site_name" content="hms-mirror Help"><meta property="og:type" content="website"><meta property="og:locale" content="en_US"><meta property="og:url" content="writerside-documentation/hms-mirror/v2.2.0.x/linking-cluster-storage-layers.html"><!-- End Open Graph --><!-- Twitter Card --><meta name="twitter:card" content="summary_large_image"><meta name="twitter:site" content=""><meta name="twitter:title" content="Linking Cluster Storage Layers | hms-mirror"><meta name="twitter:description" content=""><meta name="twitter:creator" content=""><meta name="twitter:image:src" content=""><!-- End Twitter Card --><!-- Schema.org WebPage --><script type="application/ld+json">{
    "@context": "http://schema.org",
    "@type": "WebPage",
    "@id": "writerside-documentation/hms-mirror/v2.2.0.x/linking-cluster-storage-layers.html#webpage",
    "url": "writerside-documentation/hms-mirror/v2.2.0.x/linking-cluster-storage-layers.html",
    "name": "Linking Cluster Storage Layers | hms-mirror",
    "description": "",
    "image": "",
    "inLanguage":"en-US"
}</script><!-- End Schema.org --><!-- Schema.org WebSite --><script type="application/ld+json">{
    "@type": "WebSite",
    "@id": "writerside-documentation/hms-mirror/#website",
    "url": "writerside-documentation/hms-mirror/",
    "name": "hms-mirror Help"
}</script><!-- End Schema.org --></head><body data-id="Linking-Cluster-Storage-Layers" data-main-title="Linking Cluster Storage Layers" data-article-props="{&quot;seeAlsoStyle&quot;:&quot;links&quot;}" data-template="article" data-breadcrumbs="Pre-Requisites.md|Pre-Requisites"><div class="wrapper"><main class="panel _main"><header class="panel__header"><div class="container"><h3>hms-mirror v2.2.0.x Help</h3><div class="panel-trigger"></div></div></header><section class="panel__content"><div class="container"><article class="article" data-shortcut-switcher="inactive"><h1 data-toc="Linking-Cluster-Storage-Layers" id="Linking-Cluster-Storage-Layers.md">Linking Cluster Storage Layers</h1><p id="-gff4n5_3">For the <code class="code" id="-gff4n5_9">hms-mirror</code> process to work, it relies on the RIGHT clusters' ability to <span class="emphasis" id="-gff4n5_10">SEE</span> and <span class="emphasis" id="-gff4n5_11">ACCESS</span> data in the LEFT clusters HDFS namespace. This is the same access/configuration required to support DISTCP for an HA environment and accounts for failovers.</p><p id="-gff4n5_4">We suggest that <code class="code" id="-gff4n5_12">distcp</code> operations be run from the RIGHT cluster, which usually has the greater 'hdfs' version in a migration scenario.</p><p id="-gff4n5_5">The RIGHT cluster HCFS namespace requires access to the LEFT clusters HCFS namespace. RIGHT clusters with a greater HDFS version support <span class="control" id="-gff4n5_13">LIMITED</span> functionality for data access in the LEFT cluster.</p><p id="-gff4n5_6">NOTE: This isn't designed to be a permanent solution and should only be used for testing and migration purposes.</p><section class="chapter"><h2 id="goal" data-toc="goal">Goal</h2><p id="-gff4n5_14">What does it take to support HDFS visibility between these two clusters?</p><p id="-gff4n5_15">Can that integration be used to support the Higher Clusters' use of the Lower Clusters HDFS Layer for distcp AND Hive External Table support?</p></section><section class="chapter"><h2 id="scenario-1" data-toc="scenario-1">Scenario #1</h2><section class="chapter"><h3 id="hdp-2-6-5-hadoop-2-7-x" data-toc="hdp-2-6-5-hadoop-2-7-x">HDP 2.6.5 (Hadoop 2.7.x)</h3><p id="-gff4n5_20">Kerberized - sharing same KDC as CDP Base Cluster</p><p id="-gff4n5_21"><span class="control" id="-gff4n5_31">Configuration Changes</span></p><p id="-gff4n5_22">The <span class="emphasis" id="-gff4n5_32">namenode</span> <span class="emphasis" id="-gff4n5_33">kerberos</span> principal MUST be changed from <code class="code" id="-gff4n5_34">nn</code> to <code class="code" id="-gff4n5_35">hdfs</code> to match the namenode principal of the CDP cluster.</p><p id="-gff4n5_23">Note: You may need to add/adjust the <code class="code" id="-gff4n5_36">auth_to_local</code> settings to match this change.</p><p id="-gff4n5_24">If this isn't done, <code class="code" id="-gff4n5_37">spark-shell</code> and <code class="code" id="-gff4n5_38">spark-submit</code> will fail to initialize. When changing this in Ambari on HDP, you will need to <span class="emphasis" id="-gff4n5_39">reset</span> the HDFS zkfc <code class="code" id="-gff4n5_40">ha</code> zNode in Zookeeper and reinitialize the hdfs <code class="code" id="-gff4n5_41">zkfc</code>.</p><p id="-gff4n5_25">From a Zookeeper Client: <code class="code" id="-gff4n5_42">/usr/hdp/current/zookeeper-client/bin/zkCli.sh -server localhost</code></p><div class="code-block" data-lang="none">
rmr /hadoop-ha
</div><p id="-gff4n5_27">Initialize zkfc</p><div class="code-block" data-lang="none">
hdfs zkfc -formatZK
</div><p id="-gff4n5_29"><span class="emphasis" id="-gff4n5_43">core-site.xml</span></p><div class="code-block" data-lang="none">
hadoop.rpc.protection=true
dfs.encrypt.data.transfer=true
dfs.encrypt.data.transfer.algorithm=3des
dfs.encrypt.data.transfer.cipher.key.bitlength=256
</div></section><section class="chapter"><h3 id="cdp-7-1-4-hadoop-3-1-x" data-toc="cdp-7-1-4-hadoop-3-1-x">CDP 7.1.4 (Hadoop 3.1.x)</h3><p id="-gff4n5_44">Kerberized, TLS Enabled</p><p id="-gff4n5_45"><span class="control" id="-gff4n5_51">Configuration Changes</span></p><p id="-gff4n5_46">Requirements that allow this (upper) cluster to negotiate and communicate with the lower environment.</p><p id="-gff4n5_47"><span class="emphasis" id="-gff4n5_52">Cluster Wide hdfs-site.xml Safety Value</span></p><div class="code-block" data-lang="none">
ipc.client.fallback-to-simple-auth-allowed=true
</div><p id="-gff4n5_49"><span class="emphasis" id="-gff4n5_53">HDFS Service Advanced Config hdfs-site.xml</span></p><div class="code-block" data-lang="none">
# For this Clusters Name Service
dfs.internal.nameservices=HOME90

# For the target (lower) environment HA NN Services
dfs.ha.namenodes.HDP50=nn1,nn2
dfs.namenode.rpc-address.HDP50.nn1=k01.streever.local:8020
dfs.namenode.rpc-address.HDP50.nn2=k02.streever.local:8020
dfs.namenode.http-address.HDP50.nn1=k01.streever.local:50070
dfs.namenode.http-address.HDP50.nn2=k02.streever.local:50070
dfs.namenode.https
 address.HDP50.nn1=k01.streever.local:50471
dfs.namenode.https-address.HDP50.nn2=k02.streever.local:50470
dfs.client.failover.proxy.provider.HDP50=org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider

# For Available Name Services
dfs.nameservices=HOME90,HDP50  
</div></section><section class="chapter"><h3 id="running-distcp-from-the-right-cluster" data-toc="running-distcp-from-the-right-cluster">Running <code class="code" id="-gff4n5_60">distcp</code> from the <span class="control" id="-gff4n5_61">RIGHT</span> Cluster</h3><p id="-gff4n5_55">NOTE: Running <code class="code" id="-gff4n5_62">distcp</code> from the <span class="control" id="-gff4n5_63">LEFT</span> cluster isn't supported since the <code class="code" id="-gff4n5_64">hcfs client</code> is not forward compatible.</p><p id="-gff4n5_56">Copy 'from' Lower Cluster</p><div class="code-block" data-lang="none">
hadoop distcp hdfs://HDP50/user/dstreev/sstats/queues/2020-10.txt /user/dstreev/temp
</div><p id="-gff4n5_58">Copy 'to' Lower Cluster</p><div class="code-block" data-lang="none">
hadoop distcp /warehouse/tablespace/external/hive/cvs_hathi_workload.db/queue/2020-10.txt hdfs://HDP50/user/dstreev/temp
</div></section><section class="chapter"><h3 id="sourcing-data-from-lower-cluster-to-support-upper-cluster-external-tables" data-toc="sourcing-data-from-lower-cluster-to-support-upper-cluster-external-tables">Sourcing Data from Lower Cluster to Support Upper Cluster External Tables</h3><section class="chapter"><h4 id="proxy-permissions" data-toc="proxy-permissions">Proxy Permissions</h4><p id="-gff4n5_66">The lower cluster must allow the upper clusters <span class="emphasis" id="-gff4n5_73">Hive Server 2</span> host as a 'hive' proxy. The setting in the lower clusters <span class="emphasis" id="-gff4n5_74">custom</span> <code class="code" id="-gff4n5_75">core-site.xml</code> may limit this to that clusters (lower) HS2 hosts. Open it up to include the upper clusters HS2 host.</p><p id="-gff4n5_67"><span class="emphasis" id="-gff4n5_76">Custom core-site.xml in Lower Cluster</span></p><div class="code-block" data-lang="none">
hadoop.proxyuser.hive.hosts=*
</div><p id="-gff4n5_69">Credentials from the 'upper' cluster will be projected down to the 'lower' cluster. The <code class="code" id="-gff4n5_77">hive</code> user in the upper cluster, when running with 'non-impersonation' will require access to the datasets in the lower cluster HDFS.</p><p id="-gff4n5_70">For table creation in the 'upper' clusters Metastore, a permissions check will be done on the lower environments directory for the submitting user. So, both the service user AND <code class="code" id="-gff4n5_78">hive</code> will require access to the directory location specified in the lower cluster.</p><p id="-gff4n5_71">When the two clusters <span class="emphasis" id="-gff4n5_79">share</span> accounts, and the same accounts are used between environments for users and service accounts, then access should be simple.</p><p id="-gff4n5_72">When a different set of accounts are used, the 'principal' from the upper clusters service account for 'hive' and the 'user' principal will be used in the lower cluster. This means additional HDFS policies in the lower cluster may be required to support this cross-environment work.</p></section></section></section><div class="last-modified">Last modified: 15 August 2024</div><div data-feedback-placeholder="true"></div><div class="navigation-links _bottom"><a href="hms-mirror-permissions.html" class="navigation-links__prev">Permissions</a><a href="hms-mirror-cfg.html" class="navigation-links__next">Configuration</a></div></article><div id="disqus_thread"></div></div></section></main></div><script src="https://resources.jetbrains.com/writerside/apidoc/6.10.0-b408/app.js"></script></body></html>