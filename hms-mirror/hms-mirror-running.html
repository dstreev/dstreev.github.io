<!DOCTYPE html SYSTEM "about:legacy-compat">
<html lang="en-US" data-preset="contrast" data-primary-color="#307FFF"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta charset="UTF-8"><meta name="built-on" content="2024-04-26T11:20:32.058008"><title>Running | hms-mirror</title><script type="application/json" id="virtual-toc-data">[{"id":"assumptions","level":0,"title":"Assumptions","anchor":"#assumptions"},{"id":"running-against-a-legacy-non-cdp-kerberized-hiveserver2","level":0,"title":"Running Against a LEGACY (Non-CDP) Kerberized HiveServer2","anchor":"#running-against-a-legacy-non-cdp-kerberized-hiveserver2"},{"id":"on-prem-to-cloud-migrations","level":0,"title":"On-Prem to Cloud Migrations","anchor":"#on-prem-to-cloud-migrations"},{"id":"connections","level":0,"title":"Connections","anchor":"#connections"},{"id":"troubleshooting","level":0,"title":"Troubleshooting","anchor":"#troubleshooting"}]</script><script type="application/json" id="topic-shortcuts"></script><link href="https://resources.jetbrains.com/writerside/apidoc/6.10.0-b259/app.css" rel="stylesheet"><meta name="msapplication-TileColor" content="#000000"><link rel="apple-touch-icon" sizes="180x180" href="https://jetbrains.com/apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="https://jetbrains.com/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="https://jetbrains.com/favicon-16x16.png"><meta name="msapplication-TileImage" content="https://resources.jetbrains.com/storage/ui/favicons/mstile-144x144.png"><meta name="msapplication-square70x70logo" content="https://resources.jetbrains.com/storage/ui/favicons/mstile-70x70.png"><meta name="msapplication-square150x150logo" content="https://resources.jetbrains.com/storage/ui/favicons/mstile-150x150.png"><meta name="msapplication-wide310x150logo" content="https://resources.jetbrains.com/storage/ui/favicons/mstile-310x150.png"><meta name="msapplication-square310x310logo" content="https://resources.jetbrains.com/storage/ui/favicons/mstile-310x310.png"><meta name="image" content=""><!-- Open Graph --><meta property="og:title" content="Running | hms-mirror"><meta property="og:description" content=""><meta property="og:image" content=""><meta property="og:site_name" content="hms-mirror Help"><meta property="og:type" content="website"><meta property="og:locale" content="en_US"><meta property="og:url" content="writerside-documentation/hms-mirror/v2.x/hms-mirror-running.html"><!-- End Open Graph --><!-- Twitter Card --><meta name="twitter:card" content="summary_large_image"><meta name="twitter:site" content=""><meta name="twitter:title" content="Running | hms-mirror"><meta name="twitter:description" content=""><meta name="twitter:creator" content=""><meta name="twitter:image:src" content=""><!-- End Twitter Card --><!-- Schema.org WebPage --><script type="application/ld+json">{
    "@context": "http://schema.org",
    "@type": "WebPage",
    "@id": "writerside-documentation/hms-mirror/v2.x/hms-mirror-running.html#webpage",
    "url": "writerside-documentation/hms-mirror/v2.x/hms-mirror-running.html",
    "name": "Running | hms-mirror",
    "description": "",
    "image": "",
    "inLanguage":"en-US"
}</script><!-- End Schema.org --><!-- Schema.org WebSite --><script type="application/ld+json">{
    "@type": "WebSite",
    "@id": "writerside-documentation/hms-mirror/#website",
    "url": "writerside-documentation/hms-mirror/",
    "name": "hms-mirror Help"
}</script><!-- End Schema.org --></head><body data-id="hms-mirror-running" data-main-title="Running" data-article-props="{&quot;seeAlsoStyle&quot;:&quot;links&quot;}" data-template="article" data-breadcrumbs=""><div class="wrapper"><main class="panel _main"><header class="panel__header"><div class="container"><h3>hms-mirror v2.x Help</h3><div class="panel-trigger"></div></div></header><section class="panel__content"><div class="container"><article class="article" data-shortcut-switcher="inactive"><h1 data-toc="hms-mirror-running" id="hms-mirror-running.md">Running</h1><p id="i03big_237">After running the <code class="code" id="i03big_238">setup.sh</code> script, <code class="code" id="i03big_239">hms-mirror</code> will be available in the <code class="code" id="i03big_240">$PATH</code> in a default configuration.</p><section class="chapter"><h2 id="assumptions" data-toc="assumptions">Assumptions</h2><ol class="list _decimal" id="i03big_241" type="1"><li class="list__item" id="i03big_242"><p>This process will only 'migrate' EXTERNAL and MANAGED (non-ACID/Transactional) table METADATA (not data, except with <a href="hms-mirror-sql.html" id="i03big_243" data-tooltip="The SQL data strategy will use Hive SQL to move data between clusters. When the cluster don't have direct line of sight to each other and can NOT be linked, you can use options like -cs or -is to bridge the gap.">SQL</a> and <a href="hms-mirror-export-import.html" id="i03big_244" data-tooltip="We'll use EXPORT_IMPORT to get the data to the new cluster. The default behavior requires the clusters to be linked.">EXPORT_IMPORT</a>).</p></li><li class="list__item" id="i03big_245"><p>MANAGED tables replicated to the <span class="control" id="i03big_246">RIGHT</span> cluster will be converted to &quot;EXTERNAL&quot; tables for the 'metadata' stage. They will be tagged as 'legacy managed' in the <span class="control" id="i03big_247">RIGHT</span> cluster. They will be assigned the <code class="code" id="i03big_248">external.table.purge=true</code> flag, to continue the behaviors of the legacy managed tables.</p></li><li class="list__item" id="i03big_249"><p>The <span class="control" id="i03big_250">RIGHT</span> cluster has 'line of sight' to the <span class="control" id="i03big_251">LEFT</span> cluster.</p></li><li class="list__item" id="i03big_252"><p>The <span class="control" id="i03big_253">RIGHT</span> cluster has been configured to access the <span class="control" id="i03big_254">LEFT</span> cluster storage. See <a href="linking-cluster-storage-layers.html" id="i03big_255" data-tooltip="For the hms-mirror process to work, it relies on the RIGHT clusters' ability to SEE and ACCESS data in the LEFT clusters HDFS namespace. This is the same access/configuration required to support DISTCP for an HA environment and accounts for failovers.">link clusters</a>. This is the same configuration required to support <code class="code" id="i03big_256">distcp</code> from the <span class="control" id="i03big_257">RIGHT</span> cluster to the <span class="control" id="i03big_258">LEFT</span> cluster.</p></li><li class="list__item" id="i03big_259"><p>The movement of metadata/data is from the <span class="control" id="i03big_260">LEFT</span> cluster to the <span class="control" id="i03big_261">RIGHT</span> cluster.</p></li><li class="list__item" id="i03big_262"><p>With Kerberos, each cluster must share the same trust mechanism.</p></li></ol><ul class="list _bullet" id="i03big_263"><li class="list__item" id="i03big_264"><p>The <span class="control" id="i03big_265">RIGHT</span> cluster must be Kerberized IF the <span class="control" id="i03big_266">LEFT</span> cluster is.</p></li><li class="list__item" id="i03big_267"><p>The <span class="control" id="i03big_268">LEFT</span> cluster does NOT need to be kerberized if the <span class="control" id="i03big_269">RIGHT</span> cluster is kerberized.</p></li></ul><ol class="list _decimal" id="i03big_270" type="1" start="7"><li class="list__item" id="i03big_271"><p>The * <span class="emphasis" id="i03big_272">LEFT</span> cluster does NOT have access to the <span class="control" id="i03big_273">RIGHT</span> cluster.</p></li><li class="list__item" id="i03big_274"><p>The credentials use by 'hive' (doas=false) in the <span class="control" id="i03big_275">RIGHT</span> cluster must have access to the required storage (hdfs) locations on the lower cluster.</p></li></ol><ul class="list _bullet" id="i03big_276"><li class="list__item" id="i03big_277"><p>If the <span class="control" id="i03big_278">RIGHT</span> cluster is running impersonation (doas=true), that user must have access to the required storage (hdfs) locations on the lower cluster.</p></li></ul><section class="chapter"><h3 id="transfer-data-beyond-the-metadata" data-toc="transfer-data-beyond-the-metadata">Transfer DATA, beyond the METADATA</h3><p id="i03big_279">HMS-Mirror does NOT migrate data between clusters unless you're using the <a href="hms-mirror-sql.html" id="i03big_280" data-tooltip="The SQL data strategy will use Hive SQL to move data between clusters. When the cluster don't have direct line of sight to each other and can NOT be linked, you can use options like -cs or -is to bridge the gap.">SQL</a> or <a href="hms-mirror-export-import.html" id="i03big_281" data-tooltip="We'll use EXPORT_IMPORT to get the data to the new cluster. The default behavior requires the clusters to be linked.">EXPORT_IMPORT</a> data strategies. In some cases where data is co-located, you don't need to move it. IE: Cloud to Cloud. As long as the new cluster environment has access to the original location. This is the intended target for strategies <a href="hms-mirror-common.html" id="i03big_282" data-tooltip="The data storage is shared between the two clusters, and no data migration is required.">COMMON</a> and to some extend <a href="hms-mirror-linked.html" id="i03big_283" data-tooltip="Assumes the clusters are linked. We'll transfer the schema and leave the location as is on the new cluster.">LINKED</a>.</p><p id="i03big_284">When you do need to move data, <code class="code" id="i03big_285">hms-mirror</code> creates a workbook of 'source' and 'target' locations in an output file called <code class="code" id="i03big_286">distcp_workbook.md</code>. Use this to help build a transfer job in <code class="code" id="i03big_287">distcp</code> using the <code class="code" id="i03big_288">-f</code> option to specify multiple sources.</p></section><section class="chapter"><h3 id="application-return-codes" data-toc="application-return-codes">Application Return Codes</h3><p id="i03big_289">The <code class="code" id="i03big_290">hms-mirror</code> application returns <code class="code" id="i03big_291">0</code> when everything is ok. If there is a configuration validation issue, the return code will be a negative value who's absolute value represents the bitSets cumulative <code class="code" id="i03big_292">OR</code> value. See: <a href="https://github.com/cloudera-labs/hms-mirror/blob/main/src/main/java/com/cloudera/utils/hadoop/hms/mirror/MessageCode.java" id="i03big_293" data-external="true" rel="noopener noreferrer">MessageCodes</a> for values and <a href="https://github.com/cloudera-labs/hms-mirror/blob/df9df251803d8722ef67426a73cbcfb86f981d3e/src/main/java/com/cloudera/utils/hadoop/hms/mirror/Messages.java#L26" id="i03big_294" data-external="true" rel="noopener noreferrer">Messages.java for the calculation</a>.</p><p id="i03big_295">When you receive an error code (negative value), you'll also get the items printed to the screen and the log that make up that error code.</p><p id="i03big_296">For example, the following would yield a code of <code class="code" id="i03big_297">-2305843009214742528</code> (20 and 61).</p><div class="code-block" data-lang="none">
******* ERRORS *********
20:STORAGE_MIGRATION requires you to specify PATH location for 'managed' and 'external' tables (-wd, -ewd) to migrate storage.  These will be appended to the -smn (storage-migration-namespace) parameter and used to set the 'database' LOCATION and MANAGEDLOCATION properties
61:You're using the same namespace in STORAGE_MIGRATION, without `-rdl` you'll need to ensure you have `-glm` set to map locations.
</div><p id="i03big_299"><code class="code" id="i03big_300">((2^20)+(2^61))*-1=-2305843009214742528</code></p></section></section><section class="chapter"><h2 id="running-against-a-legacy-non-cdp-kerberized-hiveserver2" data-toc="running-against-a-legacy-non-cdp-kerberized-hiveserver2">Running Against a LEGACY (Non-CDP) Kerberized HiveServer2</h2><p id="i03big_301"><code class="code" id="i03big_302">hms-mirror</code> is pre-built with CDP libraries and WILL NOT be compatible with LEGACY kerberos environments. A Kerberos connection can only be made to ONE cluster when the clusters are NOT running the same 'major' version of Hadoop.</p><p id="i03big_303">To attach to a LEGACY HS2, run <code class="code" id="i03big_304">hms-mirror</code> with the <code class="code" id="i03big_305">--hadoop-classpath</code> command-line option. This will strip the CDP libraries from <code class="code" id="i03big_306">hms-mirror</code> and use the hosts Hadoop libraries by calling <code class="code" id="i03big_307">hadoop classpath</code> to locate the binaries needed to do this.</p></section><section class="chapter"><h2 id="on-prem-to-cloud-migrations" data-toc="on-prem-to-cloud-migrations">On-Prem to Cloud Migrations</h2><p id="i03big_308">On-Prem to Cloud Migrations should run <code class="code" id="i03big_309">hms-mirror</code> from the LEFT cluster since visibility in this scenario is usually restricted to LEFT-&gt;RIGHT.</p><p id="i03big_310">If the cluster is an older version of Hadoop (HDP 2, CDH 5), your connection to the LEFT HS2 should NOT be kerberized. Use LDAP or NO_AUTH.</p><p id="i03big_311">The clusters LEFT hcfsNamespace (clusters:LEFT:hcfsNamespace) should be the LEFT clusters HDFS service endpoint. The RIGHT hcfsNamespace (clusters:RIGHT:hcfsNamespace) should be the <span class="emphasis" id="i03big_312">target</span> root cloud storage location. The LEFT clusters configuration (/etc/hadoop/conf) should have all the necessary credentials to access this location. Ensure that the cloud storage connectors are available in the LEFT environment.</p><p id="i03big_313">There are different strategies available for migrations between on-prem and cloud environments.</p><section class="chapter"><h3 id="schema-only" data-toc="schema-only">SCHEMA_ONLY</h3><p id="i03big_314">This is a schema-only transfer, where the <code class="code" id="i03big_315">hcfsNamespace</code> in the metadata definitions is 'replaced' with the <code class="code" id="i03big_316">hcfsNamespace</code> value defined on the RIGHT. NOTE: The 'relative' directory location is maintained in the migration.</p><p id="i03big_317">No data will be migrated in this case.</p><p id="i03big_318">There will be a <a href="hms-mirror-features.html#distcp-planning-workbook-and-scripts" id="i03big_319" data-tooltip="hms-mirror will create source files and a shell script that can be used as the basis for the 'distcp' job(s) used to support the databases and tables requested in -db. hms-mirror will NOT run these jobs. It will provide the basic job constructs that match what it did for theâ€¦"><code class="code" id="i03big_320">distcp</code> Planning Workbook</a> generated with a plan that can be used to build the data migration process with <code class="code" id="i03big_321">distcp</code>.</p></section><section class="chapter"><h3 id="intermediate" data-toc="intermediate">INTERMEDIATE</h3></section></section><section class="chapter"><h2 id="connections" data-toc="connections">Connections</h2><p id="i03big_322"><code class="code" id="i03big_323">hms-mirror</code> connects to 3 endpoints. The hive jdbc endpoints for each cluster (2) and the <code class="code" id="i03big_324">hdfs</code> environment configured on the running host. This means you'll need:</p><ul class="list _bullet" id="i03big_325"><li class="list__item" id="i03big_326"><p>JDBC drivers to match the JDBC endpoints</p></li><li class="list__item" id="i03big_327"><p>For <span class="control" id="i03big_328">non</span> CDP 7.x environments and Kerberos connections, an edge node with the current Hadoop libraries.</p></li></ul><p id="i03big_329">See the <a href="hms-mirror-cfg.html" id="i03big_330" data-tooltip="The configuration is done via a 'yaml' file, details below.">config</a> section to setup the config file for <code class="code" id="i03big_331">hms-mirror</code>.</p><section class="chapter"><h3 id="configuring-the-libraries" data-toc="configuring-the-libraries">Configuring the Libraries</h3><section class="chapter"><h4 id="aux-libs-classpath-additions" data-toc="aux-libs-classpath-additions">AUX_LIBS - CLASSPATH Additions</h4><section class="chapter"><h5 id="s3" data-toc="s3">S3</h5><p id="i03big_332">The directory $HOME/.hms-mirror/aux_libs will be scanned for 'jar' files. Each 'jar' will be added the java classpath of the application. Add any required libraries here.</p><p id="i03big_333">The application contains all the necessary hdfs classes already. You will need to add to the aux_libs directory the following:</p><ul class="list _bullet" id="i03big_334"><li class="list__item" id="i03big_335"><p>JDBC driver for HS2 Connectivity (only when using Kerberos)</p></li><li class="list__item" id="i03big_336"><p>AWS S3 Drivers, if s3 is used to store Hive tables. (appropriate versions) </p><ul class="list _bullet" id="i03big_337"><li class="list__item" id="i03big_338"><p>hadoop-aws.jar</p></li><li class="list__item" id="i03big_339"><p>aws-java-sdk-bundle.jar</p></li></ul></li></ul></section></section><section class="chapter"><h4 id="jdbc-connection-strings-for-hs2" data-toc="jdbc-connection-strings-for-hs2">JDBC Connection Strings for HS2</h4><p id="i03big_340">See the <a href="https://cwiki.apache.org/confluence/pages/viewpage.action?pageId=30758725#HiveServer2Clients-JDBC" id="i03big_341" data-external="true" rel="noopener noreferrer">Apache docs</a> regarding these details if you are using the environment 'Standalone' JDBC drivers. Other drivers may have different connect string requirements.</p><p id="i03big_342">The drivers for the various environments are located:</p><ul class="list _bullet" id="i03big_343"><li class="list__item" id="i03big_344"><p>HDP - <code class="code" id="i03big_345">/usr/hdp/current/hive-server2/jdbc/hive-jdbc-&lt;version&gt;-standalone.jar</code> (NOTE: Use the hive-1 standalone jar file for HDP 2.6.5, not the hive-2 jar)</p></li><li class="list__item" id="i03big_346"><p>CDH/CDP - <code class="code" id="i03big_347">/opt/cloudera/parcels/CDH/jars/hive-jdbc-&lt;version&gt;-standalone.jar</code></p></li></ul></section><section class="chapter"><h4 id="non-kerberos-connections" data-toc="non-kerberos-connections">Non-Kerberos Connections</h4><p id="i03big_348">The most effortless connections are 'non-kerberos' JDBC connections either to HS2 with AUTH models that aren't <span class="control" id="i03big_349">Kerberos</span> or through a <span class="control" id="i03big_350">Knox</span> proxy. Under these conditions, only the <span class="control" id="i03big_351">standalone</span> JDBC drivers are required. Each of the cluster configurations contains an element <code class="code" id="i03big_352">jarFile</code> to identify those standalone libraries.</p><div class="code-block" data-lang="yaml">
    hiveServer2:
      uri: &quot;&lt;jdbc-url&gt;&quot;
      connectionProperties:
        user: &quot;*****&quot;
        password: &quot;*****&quot;
      jarFile: &quot;&lt;environment-specific-jdbc-standalone-driver&gt;&quot;
</div><p id="i03big_354">When dealing with clusters supporting different Hive (Hive 1 vs. Hive 3) versions, the JDBC drivers aren't forward OR backward compatible between these versions. Hence, each JDBC jar file is loaded in a sandbox that allows us to use the same driver class, but isolates it between the two JDBC jars.</p><p id="i03big_355">Place the two jdbc jar files in any directory <span class="control" id="i03big_356">EXCEPT</span> <code class="code" id="i03big_357">$HOME/.hms-mirror/aux_libs</code> and reference the full path in the <code class="code" id="i03big_358">jarFile</code> property for that <code class="code" id="i03big_359">hiveServer2</code> configuration.</p><p id="i03big_360"><span class="emphasis" id="i03big_361">SAMPLE Commandline</span></p><p id="i03big_362"><code class="code" id="i03big_363">hms-mirror -db tpcds_bin_partitioned_orc_10</code></p></section><section class="chapter"><h4 id="kerberized-connections" data-toc="kerberized-connections">Kerberized Connections</h4><p id="i03big_364"><code class="code" id="i03big_365">hms-mirror</code> relies on the Hadoop libraries to connect via 'kerberos'. Suppose the clusters are running different versions of Hadoop/Hive. In that case, we can only support connecting to one of the clusters via Kerberos. While <code class="code" id="i03big_366">hms-mirror</code> is built with the dependencies for Hadoop 3.1 (CDP 7.1.x), we do NOT have embedded all the libraries to establish a connection to kerberos. Kerberos connections are NOT supported in the 'sandbox' configuration we discussed above.</p><p id="i03big_367">To connect to a 'kerberized' jdbc endpoint, you need to include <code class="code" id="i03big_368">--hadoop-classpath</code> with the commandline options. This will load the environments <code class="code" id="i03big_369">hadoop classpath</code> libraries for the application. To connect with a kerberos endpoint, <code class="code" id="i03big_370">hms-mirror</code> must be run on an edgenode of the platform that is kerberized to ensure we pick up the correct supporting libraries via <code class="code" id="i03big_371">hadoop classpath</code>, AND the jdbc driver for that environment must be in the <code class="code" id="i03big_372">$HOME/.hms-mirror/cfg/aux_libs</code> directory so it is a part of the applications classpath at start up. DO NOT define that environments <code class="code" id="i03big_373">jarFile</code> configuration property.</p><p id="i03big_374">There are three scenarios for kerberized connections.</p><div class="table-wrapper"><table class="wide" id="i03big_375"><thead><tr class="ijRowHead" id="i03big_376"><th id="i03big_377"><p>Scenario</p></th><th id="i03big_378"><p>LEFT Kerberized/Version</p></th><th id="i03big_379"><p>RIGHT Kerberized/Version</p></th><th id="i03big_380"><p>Notes</p></th><th id="i03big_381"><p>Sample Commandline</p></th></tr></thead><tbody><tr id="i03big_382"><td id="i03big_383"><p>1</p></td><td id="i03big_384"><p>No </p><br><p> HDP2</p></td><td id="i03big_386"><p>Yes </p><br><p> HDP 3 or CDP 7</p></td><td id="i03big_388"><ol class="list _decimal" id="i03big_389" type="1"><li class="list__item" id="i03big_390"><p>'hms-mirror' needs to be run from a node on the HDP3/CDP cluster.</p></li><li class="list__item" id="i03big_391"><p>place the RIGHT cluster jdbc jar file in <code class="code" id="i03big_392">$HOME/.hms-mirror/aux_libs</code> (yes this contradicts some earlier directions)</p></li><li class="list__item" id="i03big_393"><p>comment out the <code class="code" id="i03big_394">jarFile</code> property for the RIGHT cluster hiveServer2 setting.</p></li></ol></td><td id="i03big_395"><p><code class="code" id="i03big_396">hms-mirror -db tpcds_bin_partitioned_orc_10 --hadoop-classpath</code></p></td></tr><tr id="i03big_397"><td id="i03big_398"><p>2</p></td><td id="i03big_399"><p>YES </p><br><p> HDP 3 or CDP 7</p></td><td id="i03big_401"><p>YES </p><br><p> HDP 3 or CDP 7</p></td><td id="i03big_403"><ol class="list _decimal" id="i03big_404" type="1"><li class="list__item" id="i03big_405"><p>'hms-mirror' needs to be run from a node on the HDP3/CDP cluster.</p></li><li class="list__item" id="i03big_406"><p>place the RIGHT cluster jdbc jar file in $HOME/.hms-mirror/aux_libs (yes this contradicts some earlier directions)</p></li><li class="list__item" id="i03big_407"><p>comment out the <code class="code" id="i03big_408">jarFile</code> property for the LEFT AND RIGHT cluster hiveServer2 settings.</p></li></ol></td><td id="i03big_409"><p><code class="code" id="i03big_410">hms-mirror -db tpcds_bin_partitioned_orc_10 --hadoop-classpath</code></p></td></tr><tr id="i03big_411"><td id="i03big_412"><p>3</p></td><td id="i03big_413"><p>YES</p><br><p> HDP2 or Hive 1</p></td><td id="i03big_415"><p>NO </p><br><p> HDP 3 or CDP 7</p></td><td id="i03big_417"><p>Limited testing, but you'll need to run <code class="code" id="i03big_418">hms-mirror</code> ON the <span class="control" id="i03big_419">LEFT</span> cluster and include the LEFT clusters hive standalone jdbc driver in <code class="code" id="i03big_420">$HOME/.hms-mirror/cfg/aux_libs</code>.</p></td><td id="i03big_421"><p><code class="code" id="i03big_422">hms-mirror -db tpcds_bin_partitioned_orc_10 --hadoop-classpath</code></p></td></tr><tr id="i03big_423"><td id="i03big_424"><p>4</p></td><td id="i03big_425"><p>YES</p><br><p> HDP2 or Hive 1</p></td><td id="i03big_427"><p>YES </p><br><p> HDP2 or Hive 1</p></td><td id="i03big_429"><ol class="list _decimal" id="i03big_430" type="1"><li class="list__item" id="i03big_431"><p>The Kerberos credentials must be TRUSTED to both clusters</p></li><li class="list__item" id="i03big_432"><p>Add <code class="code" id="i03big_433">--hadoop-classpath</code> as a commandline option to <code class="code" id="i03big_434">hms-mirror</code>. This replaces the prebuilt Hadoop 3 libraries with the current environments Hadoop Libs.</p></li><li class="list__item" id="i03big_435"><p>Add the jdbc standalone jar file to <code class="code" id="i03big_436">$HOME/.hms-mirror/aux_libs</code></p></li><li class="list__item" id="i03big_437"><p>Comment out/remove the <code class="code" id="i03big_438">jarFile</code> references for BOTH clusters in the configuration file.</p></li></ol></td><td id="i03big_439"><p><code class="code" id="i03big_440">hms-mirror -db tpcds_bin_partitioned_orc_10 --hadoop-classpath</code></p></td></tr></tbody></table></div><p id="i03big_441">For Kerberos JDBC connections, ensure you are using an appropriate Kerberized Hive URL.</p><p id="i03big_442"><code class="code" id="i03big_443">jdbc:hive2://s03.streever.local:10000/;principal=hive/_HOST@STREEVER.LOCAL</code></p></section><section class="chapter"><h4 id="zookeeper-discovery-connections" data-toc="zookeeper-discovery-connections">ZooKeeper Discovery Connections</h4><p id="i03big_444">You may run into issues connecting to an older cluster using ZK Discovery. This mode brings in a LOT of the Hadoop ecosystem classes and may conflict across environments. We recommend using ZooKeeper discovery on only the RIGHT cluster. Adjust the LEFT cluster to access HS2 directly.</p></section><section class="chapter"><h4 id="tls-ssl-connections" data-toc="tls-ssl-connections">TLS/SSL Connections</h4><p id="i03big_445">If your HS2 connection requires TLS, you will need to include that detail in the jdbc 'uri' you provide. In addition, if the SSL certificate is 'self-signed' you will need to include details about the certificate to the java environment. You have 2 options:</p><ul class="list _bullet" id="i03big_446"><li class="list__item" id="i03big_447"><p>Set the JAVA_OPTS environment with the details about the certificate. </p><ul class="list _bullet" id="i03big_448"><li class="list__item" id="i03big_449"><p><code class="code" id="i03big_450">export JAVA_OPTS=-Djavax.net.ssl.trustStore=/home/dstreev/certs/gateway-client-trust.jks -Djavax.net.ssl.trustStorePassword=changeit</code></p></li></ul></li><li class="list__item" id="i03big_451"><p>Add <code class="code" id="i03big_452">-D</code> options to the <code class="code" id="i03big_453">hms-mirror</code> commandline to inject those details. </p><ul class="list _bullet" id="i03big_454"><li class="list__item" id="i03big_455"><p><code class="code" id="i03big_456">hms-mirror -db test_db -Djavax.net.ssl.trustStore=/home/dstreev/certs/gateway-client-trust.jks -Djavax.net.ssl.trustStorePassword=changeit</code></p></li></ul></li></ul></section></section></section><section class="chapter"><h2 id="troubleshooting" data-toc="troubleshooting">Troubleshooting</h2><p id="i03big_457">If each JDBC endpoint is Kerberized and the connection to the LEFT or RIGHT is successful, both NOT both, and the program seems to hang with no exception... it's most likely that the Kerberos ticket isn't TRUSTED across the two environments. You will only be able to support a Kerberos connection to the cluster where the ticket is trusted. The other cluster connection will need to be anything BUT Kerberos.</p><p id="i03big_458">Add <code class="code" id="i03big_459">--show-cp</code> to the <code class="code" id="i03big_460">hms-mirror</code> command line to see the classpath used to run.</p><p id="i03big_461">The argument <code class="code" id="i03big_462">--hadoop-classpath</code> allows us to replace the embedded Hadoop Libs (v3.1) with the libs of the current platform via a call to <code class="code" id="i03big_463">hadoop classpath</code>. This is necessary to connect to kerberized Hadoop v2/Hive v1 environments.</p><p id="i03big_464">Check the location and references to the JDBC jar files. General rules for Kerberos Connections:</p><ul class="list _bullet" id="i03big_465"><li class="list__item" id="i03big_466"><p>The JDBC jar file should be in the <code class="code" id="i03big_467">$HOME/.hms-mirror/aux_libs</code>. For Kerberos connections, we've seen issues attempting to load this jar in a sandbox, so this makes it available to the global classpath/loader.</p></li><li class="list__item" id="i03big_468"><p>Get a Kerberos ticket for the running user before launching <code class="code" id="i03big_469">hms-mirror</code>.</p></li></ul><section class="chapter"><h3 id="unrecognized-hadoop-major-version-number-3-1-1-7-1-0-257" data-toc="unrecognized-hadoop-major-version-number-3-1-1-7-1-0-257">&quot;Unrecognized Hadoop major version number: 3.1.1.7.1...0-257&quot;</h3><p id="i03big_470">This happens when you're trying to connect to an HS2 instance.</p></section></section><div class="last-modified">Last modified: 26 April 2024</div><div data-feedback-placeholder="true"></div><div class="navigation-links _bottom"><a href="hms-mirror-default-configuration-template.html" class="navigation-links__prev">Default Configuration Template</a><a href="cli-options.html" class="navigation-links__next">Commandline Help (Options)</a></div></article><div id="disqus_thread"></div></div></section></main></div><script src="https://resources.jetbrains.com/writerside/apidoc/6.10.0-b259/app.js"></script></body></html>