<!DOCTYPE html SYSTEM "about:legacy-compat">
<html lang="en-US" data-preset="contrast" data-primary-color="#307FFF"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta charset="UTF-8"><meta name="built-on" content="2025-03-31T09:07:10.468784"><title>Running | hms-mirror</title><script type="application/json" id="virtual-toc-data">[{"id":"assumptions","level":0,"title":"Assumptions","anchor":"#assumptions"},{"id":"running-against-a-legacy-non-cdp-kerberized-hiveserver2","level":0,"title":"Running Against a LEGACY (Non-CDP) Kerberized HiveServer2","anchor":"#running-against-a-legacy-non-cdp-kerberized-hiveserver2"},{"id":"on-prem-to-cloud-migrations","level":0,"title":"On-Prem to Cloud Migrations","anchor":"#on-prem-to-cloud-migrations"},{"id":"connections","level":0,"title":"Connections","anchor":"#connections"},{"id":"troubleshooting","level":0,"title":"Troubleshooting","anchor":"#troubleshooting"}]</script><script type="application/json" id="topic-shortcuts"></script><link href="https://resources.jetbrains.com/writerside/apidoc/6.22.0-b725/app.css" rel="stylesheet"><meta name="msapplication-TileColor" content="#000000"><link rel="apple-touch-icon" sizes="180x180" href="https://jetbrains.com/apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="https://jetbrains.com/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="https://jetbrains.com/favicon-16x16.png"><meta name="msapplication-TileImage" content="https://resources.jetbrains.com/storage/ui/favicons/mstile-144x144.png"><meta name="msapplication-square70x70logo" content="https://resources.jetbrains.com/storage/ui/favicons/mstile-70x70.png"><meta name="msapplication-square150x150logo" content="https://resources.jetbrains.com/storage/ui/favicons/mstile-150x150.png"><meta name="msapplication-wide310x150logo" content="https://resources.jetbrains.com/storage/ui/favicons/mstile-310x150.png"><meta name="msapplication-square310x310logo" content="https://resources.jetbrains.com/storage/ui/favicons/mstile-310x310.png"><meta name="image" content=""><!-- Open Graph --><meta property="og:title" content="Running | hms-mirror"><meta property="og:description" content=""><meta property="og:image" content=""><meta property="og:site_name" content="hms-mirror Help"><meta property="og:type" content="website"><meta property="og:locale" content="en_US"><meta property="og:url" content="writerside-documentation/hms-mirror/v2.3.1.x/hms-mirror-running.html"><!-- End Open Graph --><!-- Twitter Card --><meta name="twitter:card" content="summary_large_image"><meta name="twitter:site" content=""><meta name="twitter:title" content="Running | hms-mirror"><meta name="twitter:description" content=""><meta name="twitter:creator" content=""><meta name="twitter:image:src" content=""><!-- End Twitter Card --><!-- Schema.org WebPage --><script type="application/ld+json">{
    "@context": "http://schema.org",
    "@type": "WebPage",
    "@id": "writerside-documentation/hms-mirror/v2.3.1.x/hms-mirror-running.html#webpage",
    "url": "writerside-documentation/hms-mirror/v2.3.1.x/hms-mirror-running.html",
    "name": "Running | hms-mirror",
    "description": "",
    "image": "",
    "inLanguage":"en-US"
}</script><!-- End Schema.org --><!-- Schema.org WebSite --><script type="application/ld+json">{
    "@type": "WebSite",
    "@id": "writerside-documentation/hms-mirror/#website",
    "url": "writerside-documentation/hms-mirror/",
    "name": "hms-mirror Help"
}</script><!-- End Schema.org --></head><body data-id="hms-mirror-running" data-main-title="Running" data-article-props="{&quot;seeAlsoStyle&quot;:&quot;links&quot;}" data-template="article" data-breadcrumbs=""><div class="wrapper"><main class="panel _main"><header class="panel__header"><div class="container"><h3>hms-mirror v2.3.1.x Help</h3><div class="panel-trigger"></div></div></header><section class="panel__content"><div class="container"><article class="article" data-shortcut-switcher="inactive"><h1 data-toc="hms-mirror-running" id="hms-mirror-running.md">Running</h1><p id="-tg9i3o_3">After running the <code class="code" id="-tg9i3o_9">setup.sh</code> script, <code class="code" id="-tg9i3o_10">hms-mirror</code> will be available in the <code class="code" id="-tg9i3o_11">$PATH</code> in a default configuration.</p><section class="chapter"><h2 id="assumptions" data-toc="assumptions">Assumptions</h2><ol class="list _decimal" id="-tg9i3o_12" type="1"><li class="list__item" id="-tg9i3o_18"><p id="-tg9i3o_24">This process will only 'migrate' EXTERNAL and MANAGED (non-ACID/Transactional) table METADATA (not data, except with <a href="sql.html" id="-tg9i3o_25" data-tooltip="The SQL data strategy will use Hive SQL to move data between clusters. When the cluster don't have direct line of sight to each other and can NOT be linked, you can use options like -cs or -is to bridge the gap.">SQL</a> and <a href="export-import.html" id="-tg9i3o_26" data-tooltip="We'll use EXPORT_IMPORT to get the data to the new cluster. The default behavior requires the clusters to be linked.">EXPORT_IMPORT</a>).</p></li><li class="list__item" id="-tg9i3o_19"><p id="-tg9i3o_27">MANAGED tables replicated to the **RIGHT ** cluster will be converted to &quot;EXTERNAL&quot; tables for the 'metadata' stage. They will be tagged as 'legacy managed' in the **RIGHT ** cluster. They will be assigned the <code class="code" id="-tg9i3o_28">external.table.purge=true</code> flag, to continue the behaviors of the legacy managed tables.</p></li><li class="list__item" id="-tg9i3o_20"><p id="-tg9i3o_29">The <span class="control" id="-tg9i3o_30">RIGHT</span> cluster has 'line of sight' to the <span class="control" id="-tg9i3o_31">LEFT</span> cluster.</p></li><li class="list__item" id="-tg9i3o_21"><p id="-tg9i3o_32">The <span class="control" id="-tg9i3o_33">RIGHT</span> cluster has been configured to access the **LEFT ** cluster storage. See <a href="linking-cluster-storage-layers.html" id="-tg9i3o_34" data-tooltip="For the hms-mirror process to work, it relies on the RIGHT clusters' ability to SEE and ACCESS data in the LEFT clusters HDFS namespace. This is the same access/configuration required to support DISTCP for an HA environment and accounts for failovers.">link clusters</a>. This is the same configuration required to support <code class="code" id="-tg9i3o_35">distcp</code> from the <span class="control" id="-tg9i3o_36">RIGHT</span> cluster to the <span class="control" id="-tg9i3o_37">LEFT</span> cluster.</p></li><li class="list__item" id="-tg9i3o_22"><p id="-tg9i3o_38">The movement of metadata/data is from the <span class="control" id="-tg9i3o_39">LEFT</span> cluster to the <span class="control" id="-tg9i3o_40">RIGHT</span> cluster.</p></li><li class="list__item" id="-tg9i3o_23"><p id="-tg9i3o_41">With Kerberos, each cluster must share the same trust mechanism.</p></li></ol><ul class="list _bullet" id="-tg9i3o_13"><li class="list__item" id="-tg9i3o_42"><p id="-tg9i3o_44">The <span class="control" id="-tg9i3o_45">RIGHT</span> cluster must be Kerberized IF the <span class="control" id="-tg9i3o_46">LEFT</span> cluster is.</p></li><li class="list__item" id="-tg9i3o_43"><p id="-tg9i3o_47">The <span class="control" id="-tg9i3o_48">LEFT</span> cluster does NOT need to be kerberized if the <span class="control" id="-tg9i3o_49">RIGHT</span> cluster is kerberized.</p></li></ul><ol class="list _decimal" id="-tg9i3o_14" type="1" start="7"><li class="list__item" id="-tg9i3o_50"><p id="-tg9i3o_52">The * <span class="emphasis" id="-tg9i3o_53">LEFT</span> cluster does NOT have access to the <span class="control" id="-tg9i3o_54">RIGHT</span> cluster.</p></li><li class="list__item" id="-tg9i3o_51"><p id="-tg9i3o_55">The credentials use by 'hive' (doas=false) in the **RIGHT ** cluster must have access to the required storage (hdfs) locations on the lower cluster.</p></li></ol><ul class="list _bullet" id="-tg9i3o_15"><li class="list__item" id="-tg9i3o_56"><p id="-tg9i3o_57">If the **RIGHT ** cluster is running impersonation (doas=true), that user must have access to the required storage (hdfs) locations on the lower cluster.</p></li></ul><section class="chapter"><h3 id="transfer-data-beyond-the-metadata" data-toc="transfer-data-beyond-the-metadata">Transfer DATA, beyond the METADATA</h3><p id="-tg9i3o_58">HMS-Mirror does NOT migrate data between clusters unless you're using the <a href="sql.html" id="-tg9i3o_60" data-tooltip="The SQL data strategy will use Hive SQL to move data between clusters. When the cluster don't have direct line of sight to each other and can NOT be linked, you can use options like -cs or -is to bridge the gap.">SQL</a> or <a href="export-import.html" id="-tg9i3o_61" data-tooltip="We'll use EXPORT_IMPORT to get the data to the new cluster. The default behavior requires the clusters to be linked.">EXPORT_IMPORT</a> data strategies. In some cases where data is co-located, you don't need to move it. IE: Cloud to Cloud. As long as the new cluster environment has access to the original location. This is the intended target for strategies <a href="common.html" id="-tg9i3o_62" data-tooltip="The data storage is shared between the two clusters, and no data migration is required.">COMMON</a> and to some extend <a href="linked.html" id="-tg9i3o_63" data-tooltip="Assumes the clusters are linked. We'll transfer the schema and leave the location as is on the new cluster.">LINKED</a>.</p><p id="-tg9i3o_59">When you do need to move data, <code class="code" id="-tg9i3o_64">hms-mirror</code> creates a workbook of 'source' and 'target' locations in an output file called <code class="code" id="-tg9i3o_65">distcp_workbook.md</code>. Use this to help build a transfer job in <code class="code" id="-tg9i3o_66">distcp</code> using the <code class="code" id="-tg9i3o_67">-f</code> option to specify multiple sources.</p></section><section class="chapter"><h3 id="application-return-codes" data-toc="application-return-codes">Application Return Codes</h3><p id="-tg9i3o_68">The <code class="code" id="-tg9i3o_73">hms-mirror</code> application returns <code class="code" id="-tg9i3o_74">0</code> when everything is ok. If there is a configuration validation issue, the return code will be a negative value who's absolute value represents the bitSets cumulative <code class="code" id="-tg9i3o_75">OR</code> value. See: <a href="https://github.com/cloudera-labs/hms-mirror/blob/main/src/main/java/com/cloudera/utils/hadoop/hms/mirror/MessageCode.java" id="-tg9i3o_76" data-external="true" rel="noopener noreferrer">MessageCodes</a> for values and <a href="https://github.com/cloudera-labs/hms-mirror/blob/df9df251803d8722ef67426a73cbcfb86f981d3e/src/main/java/com/cloudera/utils/hadoop/hms/mirror/Messages.java#L26" id="-tg9i3o_77" data-external="true" rel="noopener noreferrer">Messages.java for the calculation</a>.</p><p id="-tg9i3o_69">When you receive an error code (negative value), you'll also get the items printed to the screen and the log that make up that error code.</p><p id="-tg9i3o_70">For example, the following would yield a code of <code class="code" id="-tg9i3o_78">-2305843009214742528</code> (20 and 61).</p><div class="code-block" data-lang="none">
******* ERRORS *********
20:STORAGE_MIGRATION requires you to specify PATH location for 'managed' and 'external' tables (-wd, -ewd) to migrate storage.  These will be appended to the -smn (storage-migration-namespace) parameter and used to set the 'database' LOCATION and MANAGEDLOCATION properties
61:You're using the same namespace in STORAGE_MIGRATION, without `-rdl` you'll need to ensure you have `-glm` set to map locations.
</div><p id="-tg9i3o_72"><code class="code" id="-tg9i3o_79">((2^20)+(2^61))*-1=-2305843009214742528</code></p></section></section><section class="chapter"><h2 id="running-against-a-legacy-non-cdp-kerberized-hiveserver2" data-toc="running-against-a-legacy-non-cdp-kerberized-hiveserver2">Running Against a LEGACY (Non-CDP) Kerberized HiveServer2</h2><p id="-tg9i3o_80"><code class="code" id="-tg9i3o_82">hms-mirror</code> is pre-built with CDP libraries and WILL NOT be compatible with LEGACY kerberos environments. A Kerberos connection can only be made to ONE cluster when the clusters are NOT running the same 'major' version of Hadoop.</p><p id="-tg9i3o_81">To attach to a LEGACY HS2, run <code class="code" id="-tg9i3o_83">hms-mirror</code> with the <code class="code" id="-tg9i3o_84">--hadoop-classpath</code> command-line option. This will strip the CDP libraries from <code class="code" id="-tg9i3o_85">hms-mirror</code> and use the hosts Hadoop libraries by calling <code class="code" id="-tg9i3o_86">hadoop classpath</code> to locate the binaries needed to do this.</p></section><section class="chapter"><h2 id="on-prem-to-cloud-migrations" data-toc="on-prem-to-cloud-migrations">On-Prem to Cloud Migrations</h2><p id="-tg9i3o_87">On-Prem to Cloud Migrations should run <code class="code" id="-tg9i3o_93">hms-mirror</code> from the LEFT cluster since visibility in this scenario is usually restricted to LEFT-&gt;RIGHT.</p><p id="-tg9i3o_88">If the cluster is an older version of Hadoop (HDP 2, CDH 5), your connection to the LEFT HS2 should NOT be kerberized. Use LDAP or NO_AUTH.</p><p id="-tg9i3o_89">The clusters LEFT hcfsNamespace (clusters:LEFT:hcfsNamespace) should be the LEFT clusters HDFS service endpoint. The RIGHT hcfsNamespace (clusters:RIGHT:hcfsNamespace) should be the <span class="emphasis" id="-tg9i3o_94">target</span> root cloud storage location. The LEFT clusters configuration (/etc/hadoop/conf) should have all the necessary credentials to access this location. Ensure that the cloud storage connectors are available in the LEFT environment.</p><p id="-tg9i3o_90">There are different strategies available for migrations between on-prem and cloud environments.</p><section class="chapter"><h3 id="schema-only" data-toc="schema-only">SCHEMA_ONLY</h3><p id="-tg9i3o_95">This is a schema-only transfer, where the <code class="code" id="-tg9i3o_98">hcfsNamespace</code> in the metadata definitions is 'replaced' with the <code class="code" id="-tg9i3o_99">hcfsNamespace</code> value defined on the RIGHT. NOTE: The 'relative' directory location is maintained in the migration.</p><p id="-tg9i3o_96">No data will be migrated in this case.</p><p id="-tg9i3o_97">There will be a <a href="hms-mirror-features.html#distcp-planning-workbook-and-scripts" id="-tg9i3o_100" data-tooltip="hms-mirror will create source files and a shell script that can be used as the basis for the 'distcp' job(s) used to support the databases and tables requested in -db. hms-mirror will NOT run these jobs. It will provide the basic job constructs that match what it did for the…"><code class="code" id="-tg9i3o_102">distcp</code> Planning Workbook</a> generated with a plan that can be used to build the data migration process with <code class="code" id="-tg9i3o_101">distcp</code>.</p></section><section class="chapter"><h3 id="intermediate" data-toc="intermediate">INTERMEDIATE</h3></section></section><section class="chapter"><h2 id="connections" data-toc="connections">Connections</h2><p id="-tg9i3o_103"><code class="code" id="-tg9i3o_107">hms-mirror</code> connects to 3 endpoints. The hive jdbc endpoints for each cluster (2) and the <code class="code" id="-tg9i3o_108">hdfs</code> environment configured on the running host. This means you'll need:</p><ul class="list _bullet" id="-tg9i3o_104"><li class="list__item" id="-tg9i3o_109"><p id="-tg9i3o_111">JDBC drivers to match the JDBC endpoints</p></li><li class="list__item" id="-tg9i3o_110"><p id="-tg9i3o_112">For <span class="control" id="-tg9i3o_113">non</span> CDP 7.x environments and Kerberos connections, an edge node with the current Hadoop libraries.</p></li></ul><p id="-tg9i3o_105">See the <a href="hms-mirror-cfg.html" id="-tg9i3o_114" data-tooltip="hms-mirror defines clusters as LEFT and RIGHT. The LEFT cluster is the source of the metadata and the RIGHT cluster is the target. The LEFT cluster is usually the older cluster version. Regardless, under specific scenario's, hms-mirror will use an HDFS client to check directories…">config</a> section to setup the config file for <code class="code" id="-tg9i3o_115">hms-mirror</code>.</p><section class="chapter"><h3 id="configuring-the-libraries" data-toc="configuring-the-libraries">Configuring the Libraries</h3><section class="chapter"><h4 id="aux-libs-classpath-additions" data-toc="aux-libs-classpath-additions">AUX_LIBS - CLASSPATH Additions</h4><section class="chapter"><h5 id="s3" data-toc="s3">S3</h5><p id="-tg9i3o_123">The directory $HOME/.hms-mirror/aux_libs will be scanned for 'jar' files. Each 'jar' will be added the java classpath of the application. Add any required libraries here.</p><p id="-tg9i3o_124">The application contains all the necessary hdfs classes already. You will need to add to the aux_libs directory the following:</p><ul class="list _bullet" id="-tg9i3o_125"><li class="list__item" id="-tg9i3o_126"><p id="-tg9i3o_128">JDBC driver for HS2 Connectivity (only when using Kerberos)</p></li><li class="list__item" id="-tg9i3o_127"><p id="-tg9i3o_129">AWS S3 Drivers, if s3 is used to store Hive tables. (appropriate versions)</p><ul class="list _bullet" id="-tg9i3o_130"><li class="list__item" id="-tg9i3o_131"><p id="-tg9i3o_133">hadoop-aws.jar</p></li><li class="list__item" id="-tg9i3o_132"><p id="-tg9i3o_134">aws-java-sdk-bundle.jar</p></li></ul></li></ul></section></section><section class="chapter"><h4 id="jdbc-connection-strings-for-hs2" data-toc="jdbc-connection-strings-for-hs2">JDBC Connection Strings for HS2</h4><p id="-tg9i3o_135">See the <a href="https://cwiki.apache.org/confluence/pages/viewpage.action?pageId=30758725#HiveServer2Clients-JDBC" id="-tg9i3o_138" data-external="true" rel="noopener noreferrer">Apache docs</a> regarding these details if you are using the environment 'Standalone' JDBC drivers. Other drivers may have different connect string requirements.</p><p id="-tg9i3o_136">The drivers for the various environments are located:</p><ul class="list _bullet" id="-tg9i3o_137"><li class="list__item" id="-tg9i3o_139"><p id="-tg9i3o_141">HDP - <code class="code" id="-tg9i3o_142">/usr/hdp/current/hive-server2/jdbc/hive-jdbc-&lt;version&gt;-standalone.jar</code> (NOTE: Use the hive-1 standalone jar file for HDP 2.6.5, not the hive-2 jar)</p></li><li class="list__item" id="-tg9i3o_140"><p id="-tg9i3o_143">CDH/CDP - <code class="code" id="-tg9i3o_144">/opt/cloudera/parcels/CDH/jars/hive-jdbc-&lt;version&gt;-standalone.jar</code></p></li></ul></section><section class="chapter"><h4 id="non-kerberos-connections" data-toc="non-kerberos-connections">Non-Kerberos Connections</h4><p id="-tg9i3o_145">The most effortless connections are 'non-kerberos' JDBC connections either to HS2 with AUTH models that aren't * <span class="emphasis" id="-tg9i3o_151">Kerberos</span>* or through a <span class="control" id="-tg9i3o_152">Knox</span> proxy. Under these conditions, only the __standalone __ JDBC drivers are required. Each of the cluster configurations contains an element <code class="code" id="-tg9i3o_153">jarFile</code> to identify those standalone libraries.</p><div class="code-block" data-lang="yaml">
    hiveServer2:
      uri: &quot;&lt;jdbc-url&gt;&quot;
      connectionProperties:
        user: &quot;*****&quot;
        password: &quot;*****&quot;
      jarFile: &quot;&lt;environment-specific-jdbc-standalone-driver&gt;&quot;
</div><p id="-tg9i3o_147">When dealing with clusters supporting different Hive (Hive 1 vs. Hive 3) versions, the JDBC drivers aren't forward OR backward compatible between these versions. Hence, each JDBC jar file is loaded in a sandbox that allows us to use the same driver class, but isolates it between the two JDBC jars.</p><p id="-tg9i3o_148">Place the two jdbc jar files in any directory **EXCEPT ** <code class="code" id="-tg9i3o_154">$HOME/.hms-mirror/aux_libs</code> and reference the full path in the <code class="code" id="-tg9i3o_155">jarFile</code> property for that <code class="code" id="-tg9i3o_156">hiveServer2</code> configuration.</p><p id="-tg9i3o_149"><span class="emphasis" id="-tg9i3o_157">SAMPLE Commandline</span></p><p id="-tg9i3o_150"><code class="code" id="-tg9i3o_158">hms-mirror -db tpcds_bin_partitioned_orc_10</code></p></section><section class="chapter"><h4 id="kerberized-connections" data-toc="kerberized-connections">Kerberized Connections</h4><p id="-tg9i3o_159"><code class="code" id="-tg9i3o_166">hms-mirror</code> relies on the Hadoop libraries to connect via 'kerberos'. Suppose the clusters are running different versions of Hadoop/Hive. In that case, we can only support connecting to one of the clusters via Kerberos.</p><aside class="prompt" data-type="warning" data-title="" id="-tg9i3o_160"><p>Packaging improvements in version 2.x include all the Kerberos libraries you need to connection to a kerberized Hive Server2 and HDFS. The `--hadoop-classpath` option is no longer required for Kerberos connections. The application will use the embedded Hadoop 3.1 libraries to connect to the kerberized endpoints. The `--hadoop-classpath` option is still available for connecting to older Hadoop 2.x environments.</p></aside><aside class="prompt" data-type="note" data-title="" id="-tg9i3o_161"><p>The `jarFile` property is NOT used for Kerberos connections. The JDBC jar file for the kerberized cluster should be placed in the `$HOME/.hms-mirror/aux_libs` directory.</p></aside><p id="-tg9i3o_162">There are three scenarios for kerberized connections.</p><div class="table-wrapper"><table class="wide" id="-tg9i3o_163"><thead><tr class="ijRowHead" id="-tg9i3o_167"><th id="-tg9i3o_172"><p>Scenario</p></th><th id="-tg9i3o_173"><p>LEFT Kerberized/Version</p></th><th id="-tg9i3o_174"><p>RIGHT Kerberized/Version</p></th><th id="-tg9i3o_175"><p>Notes</p></th><th id="-tg9i3o_176"><p>Sample Commandline</p></th></tr></thead><tbody><tr id="-tg9i3o_168"><td id="-tg9i3o_177"><p>1</p></td><td id="-tg9i3o_178"><p>No <br> HDP2</p></td><td id="-tg9i3o_179"><p>Yes <br> HDP 3 or CDP 7</p></td><td id="-tg9i3o_180"><ol class="list _decimal" id="-tg9i3o_184" type="1"><li class="list__item" id="-tg9i3o_185"><p>'hms-mirror' needs to be run from a node on the HDP3/CDP cluster.</p></li><li class="list__item" id="-tg9i3o_186"><p>place the RIGHT cluster jdbc jar file in `$HOME/.hms-mirror/aux_libs` (yes this contradicts some earlier directions)</p></li><li class="list__item" id="-tg9i3o_187"><p>comment out the `jarFile` property for the RIGHT cluster hiveServer2 setting.</p></li></ol></td><td id="-tg9i3o_181"><p>`hms-mirror -db tpcds_bin_partitioned_orc_10 --hadoop-classpath`</p></td></tr><tr id="-tg9i3o_169"><td id="-tg9i3o_188"><p>2</p></td><td id="-tg9i3o_189"><p>YES <br> HDP 3 or CDP 7</p></td><td id="-tg9i3o_190"><p>YES <br> HDP 3 or CDP 7</p></td><td id="-tg9i3o_191"><ol class="list _decimal" id="-tg9i3o_195" type="1"><li class="list__item" id="-tg9i3o_196"><p>'hms-mirror' needs to be run from a node on the HDP3/CDP cluster.</p></li><li class="list__item" id="-tg9i3o_197"><p>place the RIGHT cluster jdbc jar file in $HOME/.hms-mirror/aux_libs (yes this contradicts some earlier directions)</p></li><li class="list__item" id="-tg9i3o_198"><p>comment out the `jarFile` property for the LEFT AND RIGHT cluster hiveServer2 settings.</p></li></ol></td><td id="-tg9i3o_192"><p>`hms-mirror -db tpcds_bin_partitioned_orc_10 --hadoop-classpath`</p></td></tr><tr id="-tg9i3o_170"><td id="-tg9i3o_199"><p>3</p></td><td id="-tg9i3o_200"><p>YES <br> HDP 2 or Hive 1</p></td><td id="-tg9i3o_201"><p>NO <br> HDP 3 or CDP 7</p></td><td id="-tg9i3o_202"><p>Limited testing, but you'll need to run `hms-mirror` ON the **LEFT** cluster and include the LEFT clusters hive standalone jdbc driver in `$HOME/.hms-mirror/cfg/aux_libs`.</p></td><td id="-tg9i3o_203"><p>`hms-mirror -db tpcds_bin_partitioned_orc_10 --hadoop-classpath`</p></td></tr><tr id="-tg9i3o_171"><td id="-tg9i3o_206"><p>4</p></td><td id="-tg9i3o_207"><p>YES <br> HDP 2 or Hive 1</p></td><td id="-tg9i3o_208"><p>YES <br> HDP 2 or Hive 1</p></td><td id="-tg9i3o_209"><ol class="list _decimal" id="-tg9i3o_213" type="1"><li class="list__item" id="-tg9i3o_214"><p>The Kerberos credentials must be TRUSTED to both clusters</p></li><li class="list__item" id="-tg9i3o_215"><p>Add `--hadoop-classpath` as a commandline option to `hms-mirror`. This replaces the prebuilt Hadoop 3 libraries with the current environments Hadoop Libs.</p></li><li class="list__item" id="-tg9i3o_216"><p>Add the jdbc standalone jar file to `$HOME/.hms-mirror/aux_libs`</p></li><li class="list__item" id="-tg9i3o_217"><p>Comment out/remove the `jarFile` references for BOTH clusters in the configuration file.</p></li></ol></td><td id="-tg9i3o_210"><p>`hms-mirror -db tpcds_bin_partitioned_orc_10 --hadoop-classpath`</p></td></tr></tbody></table></div><p id="-tg9i3o_164">For Kerberos JDBC connections, ensure you are using an appropriate Kerberized Hive URL.</p><p id="-tg9i3o_165"><code class="code" id="-tg9i3o_218">jdbc:hive2://s03.streever.local:10000/;principal=hive/_HOST@STREEVER.LOCAL</code></p></section><section class="chapter"><h4 id="zookeeper-discovery-connections" data-toc="zookeeper-discovery-connections">ZooKeeper Discovery Connections</h4><p id="-tg9i3o_219">You may run into issues connecting to an older cluster using ZK Discovery. This mode brings in a LOT of the Hadoop ecosystem classes and may conflict across environments. We recommend using ZooKeeper discovery on only the RIGHT cluster. Adjust the LEFT cluster to access HS2 directly.</p></section><section class="chapter"><h4 id="tls-ssl-connections" data-toc="tls-ssl-connections">TLS/SSL Connections</h4><p id="-tg9i3o_220">If your HS2 connection requires TLS, you will need to include that detail in the jdbc 'uri' you provide. In addition, if the SSL certificate is 'self-signed' you will need to include details about the certificate to the java environment. You have 2 options:</p><ul class="list _bullet" id="-tg9i3o_221"><li class="list__item" id="-tg9i3o_222"><p id="-tg9i3o_224">Set the JAVA_OPTS environment with the details about the certificate.</p><ul class="list _bullet" id="-tg9i3o_225"><li class="list__item" id="-tg9i3o_226"><p id="-tg9i3o_227"><code class="code" id="-tg9i3o_228">export JAVA_OPTS=-Djavax.net.ssl.trustStore=/home/dstreev/certs/gateway-client-trust.jks -Djavax.net.ssl.trustStorePassword=changeit</code></p></li></ul></li><li class="list__item" id="-tg9i3o_223"><p id="-tg9i3o_229">Add <code class="code" id="-tg9i3o_231">-D</code> options to the <code class="code" id="-tg9i3o_232">hms-mirror</code> commandline to inject those details.</p><ul class="list _bullet" id="-tg9i3o_230"><li class="list__item" id="-tg9i3o_233"><p id="-tg9i3o_234"><code class="code" id="-tg9i3o_235">hms-mirror -db test_db -Djavax.net.ssl.trustStore=/home/dstreev/certs/gateway-client-trust.jks -Djavax.net.ssl.trustStorePassword=changeit</code></p></li></ul></li></ul></section></section></section><section class="chapter"><h2 id="troubleshooting" data-toc="troubleshooting">Troubleshooting</h2><p id="-tg9i3o_236">If each JDBC endpoint is Kerberized and the connection to the LEFT or RIGHT is successful, both NOT both, and the program seems to hang with no exception... it's most likely that the Kerberos ticket isn't TRUSTED across the two environments. You will only be able to support a Kerberos connection to the cluster where the ticket is trusted. The other cluster connection will need to be anything BUT Kerberos.</p><p id="-tg9i3o_237">Add <code class="code" id="-tg9i3o_242">--show-cp</code> to the <code class="code" id="-tg9i3o_243">hms-mirror</code> command line to see the classpath used to run.</p><p id="-tg9i3o_238">The argument <code class="code" id="-tg9i3o_244">--hadoop-classpath</code> allows us to replace the embedded Hadoop Libs (v3.1) with the libs of the current platform via a call to <code class="code" id="-tg9i3o_245">hadoop classpath</code>. This is necessary to connect to kerberized Hadoop v2/Hive v1 environments.</p><p id="-tg9i3o_239">Check the location and references to the JDBC jar files. General rules for Kerberos Connections:</p><ul class="list _bullet" id="-tg9i3o_240"><li class="list__item" id="-tg9i3o_246"><p id="-tg9i3o_248">The JDBC jar file should be in the <code class="code" id="-tg9i3o_249">$HOME/.hms-mirror/aux_libs</code>. For Kerberos connections, we've seen issues attempting to load this jar in a sandbox, so this makes it available to the global classpath/loader.</p></li><li class="list__item" id="-tg9i3o_247"><p id="-tg9i3o_250">Get a Kerberos ticket for the running user before launching <code class="code" id="-tg9i3o_251">hms-mirror</code>.</p></li></ul><section class="chapter"><h3 id="unrecognized-hadoop-major-version-number-3-1-1-7-1-0-257" data-toc="unrecognized-hadoop-major-version-number-3-1-1-7-1-0-257">&quot;Unrecognized Hadoop major version number: 3.1.1.7.1...0-257&quot;</h3><p id="-tg9i3o_252">This happens when you're trying to connect to an HS2 instance.</p></section></section><div class="last-modified">Last modified: 31 March 2025</div><div data-feedback-placeholder="true"></div><div class="navigation-links _bottom"><a href="hms-mirror-default-configuration-template.html" class="navigation-links__prev">Default Configuration Template</a><a href="hms-mirror-optimizations.html" class="navigation-links__next">Optimizations</a></div></article><div id="disqus_thread"></div></div></section></main></div><script src="https://resources.jetbrains.com/writerside/apidoc/6.22.0-b725/app.js"></script></body></html>