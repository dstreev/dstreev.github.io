<!DOCTYPE html SYSTEM "about:legacy-compat">
<html lang="en-US" data-preset="contrast" data-primary-color="#307FFF"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta charset="UTF-8"><meta name="built-on" content="2025-01-25T09:19:35.295348"><title>Cloud to Cloud DR (AWS) | hms-mirror</title><script type="application/json" id="virtual-toc-data">[{"id":"requirements","level":0,"title":"Requirements","anchor":"#requirements"},{"id":"assumptions","level":0,"title":"Assumptions","anchor":"#assumptions"},{"id":"the-process","level":0,"title":"The Process","anchor":"#the-process"},{"id":"running-hms-mirror","level":0,"title":"Running hms-mirror","anchor":"#running-hms-mirror"}]</script><script type="application/json" id="topic-shortcuts"></script><link href="https://resources.jetbrains.com/writerside/apidoc/6.10.0-b575/app.css" rel="stylesheet"><meta name="msapplication-TileColor" content="#000000"><link rel="apple-touch-icon" sizes="180x180" href="https://jetbrains.com/apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="https://jetbrains.com/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="https://jetbrains.com/favicon-16x16.png"><meta name="msapplication-TileImage" content="https://resources.jetbrains.com/storage/ui/favicons/mstile-144x144.png"><meta name="msapplication-square70x70logo" content="https://resources.jetbrains.com/storage/ui/favicons/mstile-70x70.png"><meta name="msapplication-square150x150logo" content="https://resources.jetbrains.com/storage/ui/favicons/mstile-150x150.png"><meta name="msapplication-wide310x150logo" content="https://resources.jetbrains.com/storage/ui/favicons/mstile-310x150.png"><meta name="msapplication-square310x310logo" content="https://resources.jetbrains.com/storage/ui/favicons/mstile-310x310.png"><meta name="image" content=""><!-- Open Graph --><meta property="og:title" content="Cloud to Cloud DR (AWS) | hms-mirror"><meta property="og:description" content=""><meta property="og:image" content=""><meta property="og:site_name" content="hms-mirror Help"><meta property="og:type" content="website"><meta property="og:locale" content="en_US"><meta property="og:url" content="writerside-documentation/hms-mirror/v2.2.0.x/cloud-to-cloud-dr.html"><!-- End Open Graph --><!-- Twitter Card --><meta name="twitter:card" content="summary_large_image"><meta name="twitter:site" content=""><meta name="twitter:title" content="Cloud to Cloud DR (AWS) | hms-mirror"><meta name="twitter:description" content=""><meta name="twitter:creator" content=""><meta name="twitter:image:src" content=""><!-- End Twitter Card --><!-- Schema.org WebPage --><script type="application/ld+json">{
    "@context": "http://schema.org",
    "@type": "WebPage",
    "@id": "writerside-documentation/hms-mirror/v2.2.0.x/cloud-to-cloud-dr.html#webpage",
    "url": "writerside-documentation/hms-mirror/v2.2.0.x/cloud-to-cloud-dr.html",
    "name": "Cloud to Cloud DR (AWS) | hms-mirror",
    "description": "",
    "image": "",
    "inLanguage":"en-US"
}</script><!-- End Schema.org --><!-- Schema.org WebSite --><script type="application/ld+json">{
    "@type": "WebSite",
    "@id": "writerside-documentation/hms-mirror/#website",
    "url": "writerside-documentation/hms-mirror/",
    "name": "hms-mirror Help"
}</script><!-- End Schema.org --></head><body data-id="cloud_to_cloud_dr" data-main-title="Cloud to Cloud DR (AWS)" data-article-props="{&quot;seeAlsoStyle&quot;:&quot;links&quot;}" data-template="article" data-breadcrumbs="use-cases.md|Use Cases"><div class="wrapper"><main class="panel _main"><header class="panel__header"><div class="container"><h3>hms-mirror v2.2.0.x Help</h3><div class="panel-trigger"></div></div></header><section class="panel__content"><div class="container"><article class="article" data-shortcut-switcher="inactive"><h1 data-toc="cloud_to_cloud_dr" id="cloud_to_cloud_dr.md">Cloud to Cloud DR (AWS)</h1><p id="xburrf_3">We'll cover how to manage a DR scenario where the source cluster is in the cloud and the target cluster is also in the cloud. The main elements to consider are:</p><ul class="list _bullet" id="xburrf_4"><li class="list__item" id="xburrf_9"><p>Hive Metadata (Tables, Databases, Views)</p></li><li class="list__item" id="xburrf_10"><p>Data on S3</p></li></ul><section class="chapter"><h2 id="requirements" data-toc="requirements">Requirements</h2><ul class="list _bullet" id="xburrf_11"><li class="list__item" id="xburrf_12"><p>The source and target clusters on AWS are running CDP Cloud with an available HS2 endpoint.</p></li><li class="list__item" id="xburrf_13"><p>Provide a mechanism to migrate Hive metadata from the source cluster to the target cluster, to include making adjustments to the metadata to account for differences in the clusters storage locations.</p></li><li class="list__item" id="xburrf_14"><p>Establish the RPO and RTO for the DR scenario and ensure the migration process can meet those requirements.</p></li><li class="list__item" id="xburrf_15"><p>We'll only target <span class="control" id="xburrf_16">external</span> tables for this scenario. Managed tables will require additional considerations, since the data and metadata are intermingled and can't be supported through a simple copy operation.</p></li></ul></section><section class="chapter"><h2 id="assumptions" data-toc="assumptions">Assumptions</h2><ul class="list _bullet" id="xburrf_17"><li class="list__item" id="xburrf_18"><p>The data on S3 is already replicated to the target cluster through some other mechanism (e.g. S3 replication, etc.).</p></li><li class="list__item" id="xburrf_19"><p>The S3 replication will meet the RPO and RTO requirements.</p></li><li class="list__item" id="xburrf_20"><p>The data replication is in place before DR is invoked and the scripts are run to build the schemas on the target cluster.</p></li><li class="list__item" id="xburrf_21"><p>There are no managed tables being migrated. I would recommend setting the database property <code class="code" id="xburrf_25">&lsquo;EXTERNAL_TABLES_ONLY&rsquo;=&rsquo;TRUE&rsquo;</code> with: <code class="code" id="xburrf_26">ALTER DATABASE &lt;db_name&gt; SET TBLPROPERTIES ('EXTERNAL_TABLES_ONLY'='TRUE');</code> to ensure only external tables can be created.</p></li><li class="list__item" id="xburrf_22"><p>Partitions follow standard naming conventions regarding directory names/structures. Tables with non-standard partitioning will require additional considerations. <code class="code" id="xburrf_27">hms-mirror</code> doesn't translate partition details and relies on <code class="code" id="xburrf_28">MSCK REPAIR &lt;table&gt; SYNC PARTITIONS</code> to discover / rebuild a tables partitions. If the partitions are not in a standard format, the <code class="code" id="xburrf_29">MSCK REPAIR</code> will not work and the partitions will need to be manually created.</p></li><li class="list__item" id="xburrf_23"><p>We don't support schema evolution. All tables will be created in there current state.</p></li><li class="list__item" id="xburrf_24"><p>The &quot;LEFT&quot; clusters <code class="code" id="xburrf_30">hcfsNamespace</code> can only address a single namespace at a time. If you have multiple namespaces, you'll need to run <code class="code" id="xburrf_31">hms-mirror</code> multiple times, once for each namespace. The &quot;RIGHT&quot; cluster can address multiple namespaces through the <code class="code" id="xburrf_32">hcfsNamespace</code> element. This element is used to match and adjust the storage location of the tables on the target cluster.</p></li></ul></section><section class="chapter"><h2 id="the-process" data-toc="the-process">The Process</h2><p id="xburrf_33">The process is fairly straight forward. We'll use <code class="code" id="xburrf_36">hms-mirror</code> to migrate the Hive metadata from the source cluster to the target cluster. We'll use the <code class="code" id="xburrf_37">--common-storage</code> or set the <code class="code" id="xburrf_38">hcfsNamespace</code> element for the RIGHT cluster to ensure the schemas are built with the DR bucket adjustments.</p><p id="xburrf_34">You have a few options regarding the transfer:</p><ul class="list _bullet" id="xburrf_35"><li class="list__item" id="xburrf_39"><p>If the target is truly a DR cluster, you can run <code class="code" id="xburrf_41">hms-mirror</code> on the source cluster and generate the metadata files locally. Then copy the metadata files to the target cluster and build out the schemas there. This doesn't need to be done until the DR is invoked.</p></li><li class="list__item" id="xburrf_40"><p>If you want/need to keep the metadata in-sync between the clusters, you can run <code class="code" id="xburrf_42">hms-mirror</code> with the <code class="code" id="xburrf_43">-ro</code> and <code class="code" id="xburrf_44">-sync</code> flags (and eventually with <code class="code" id="xburrf_45">-e</code>) to keep the metadata in-sync between the clusters. Tables created on the source cluster will require the data to be replicated to the target cluster before the table can be created in DR. While we're only migrating <span class="emphasis" id="xburrf_46">external</span> tables, they may have set <code class="code" id="xburrf_47">external.table.purge</code> to <code class="code" id="xburrf_48">true</code> on the source cluster. In this case, these tables will be set to <span class="control" id="xburrf_49">NON</span> purge on the target cluster. This is to prevent the table data (being managed through S3 replication) from being dropped by subsequent sync runs where the tables might have changed.</p></li></ul></section><section class="chapter"><h2 id="running-hms-mirror" data-toc="running-hms-mirror">Running <code class="code" id="xburrf_53">hms-mirror</code></h2><section class="chapter"><h3 id="configuration" data-toc="configuration">Configuration</h3><p id="xburrf_54">This file should be named <code class="code" id="xburrf_56">$HOME/.hms-mirror/cfg/default.yaml</code></p><div class="code-block" data-lang="yaml">
clusters:
  LEFT:
    environment: &quot;LEFT&quot;
    legacyHive: false
    hcfsNamespace: &quot;s3a://&lt;my_source_s3_bucket&gt;&quot;
    hiveServer2:
      # Recommend using a KNOX endpoint to remove need for Kerberos Authentication
      uri: &quot;jdbc:hive2://&lt;my_source_hs2_endpoint&gt;&quot;
      connectionProperties:
        user: &quot;&lt;user&gt;&quot;
        maxWaitMillis: &quot;5000&quot;
        password: &quot;*****&quot;
        maxTotal: &quot;-1&quot;
      jarFile: &quot;&lt;local_location_of_hive-jdbc_driver&gt;&quot;
  RIGHT:
    environment: &quot;RIGHT&quot;
    legacyHive: false
    hcfsNamespace: &quot;s3a://&lt;my_target_s3_bucket&gt;&quot;
    hiveServer2:
      uri: &quot;jdbc:hive2://&lt;my_target_hs2_endpoint&gt;&quot;
      connectionProperties:
        user: &quot;&lt;user&gt;&quot;
        maxWaitMillis: &quot;5000&quot;
        password: &quot;*****&quot;
        maxTotal: &quot;-1&quot;
      jarFile: &quot;&lt;local_location_of_hive-jdbc_driver&gt;&quot;
    partitionDiscovery:
      # Optional, but recommended it the cluster isn't overburdened.
      auto: true
      # Required if auto is false and/or you want to ensure the partitions are in sync after the 
      # transfer is made.
      initMSCK: true
</div></section><section class="chapter"><h3 id="command-lines" data-toc="command-lines">Command Lines</h3><p id="xburrf_57"><code class="code" id="xburrf_58">hms-mirror --hadoop-classpath -d SCHEMA_ONLY -db &lt;db_comma_separated_list&gt; -ro -sync</code></p></section></section><div class="last-modified">Last modified: 25 January 2025</div><div data-feedback-placeholder="true"></div><div class="navigation-links _bottom"><a href="hms-mirror-leg-non-leg-scenarios.html" class="navigation-links__prev">Scenarios</a><a href="hms-mirror-hybrid-data-lakehouse.html" class="navigation-links__next">Hybrid Data LakeHouse</a></div></article><div id="disqus_thread"></div></div></section></main></div><script src="https://resources.jetbrains.com/writerside/apidoc/6.10.0-b575/app.js"></script></body></html>