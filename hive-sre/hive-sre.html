<!DOCTYPE html SYSTEM "about:legacy-compat"><html lang="en-US" data-colors-preset="contrast" data-primary-color="#307FFF"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta charset="UTF-8"><meta name="robots" content="noindex">  <meta name="built-on" content="2023-11-06T11:07:20.608302"><meta name="build-number" content="${buildNumber}">       <title>Introduction | hive-sre</title><script id="virtual-toc-data" type="application/json">[{"id":"supported-metastore-db-s","level":0,"title":"Supported Metastore DB\u0027s","anchor":"#supported-metastore-db-s"},{"id":"hadoop-cli","level":0,"title":"Hadoop CLI","anchor":"#hadoop-cli"},{"id":"ping-performance-tool","level":0,"title":"Ping Performance Tool","anchor":"#ping-performance-tool"}]</script><script id="topic-shortcuts" type="application/json"></script><link href="https://resources.jetbrains.com/writerside/apidoc/6.1.5-b176/app.css" rel="stylesheet">   <link rel="apple-touch-icon" sizes="180x180" href="https://jetbrains.com/apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="https://jetbrains.com/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="https://jetbrains.com/favicon-16x16.png"><link rel="manifest" href="https://jetbrains.com/site.webmanifest"><link rel="mask-icon" href="https://jetbrains.com/safari-pinned-tab.svg" color="#000000"><meta name="msapplication-TileColor" content="#000000"/><meta name="msapplication-TileImage" content="https://resources.jetbrains.com/storage/ui/favicons/mstile-144x144.png"/><meta name="msapplication-square70x70logo" content="https://resources.jetbrains.com/storage/ui/favicons/mstile-70x70.png"/><meta name="msapplication-square150x150logo" content="https://resources.jetbrains.com/storage/ui/favicons/mstile-150x150.png"/><meta name="msapplication-wide310x150logo" content="https://resources.jetbrains.com/storage/ui/favicons/mstile-310x150.png"/><meta name="msapplication-square310x310logo" content="https://resources.jetbrains.com/storage/ui/favicons/mstile-310x310.png"/>  <meta name="image" content=""><!-- Open Graph --><meta property="og:title" content="Introduction | hive-sre"/><meta property="og:description" content=""/><meta property="og:image" content=""/><meta property="og:site_name" content="hive-sre Help"/><meta property="og:type" content="website"/><meta property="og:locale" content="en_US"/><meta property="og:url" content="hive-srehive-sre.html"/><!-- End Open Graph --><!-- Twitter Card --><meta name="twitter:card" content="summary_large_image"><meta name="twitter:site" content=""><meta name="twitter:title" content="Introduction | hive-sre"><meta name="twitter:description" content=""><meta name="twitter:creator" content=""><meta name="twitter:image:src" content=""><!-- End Twitter Card --><!-- Schema.org WebPage --><script type="application/ld+json"> { "@context": "http://schema.org", "@type": "WebPage", "@id": "hive-srehive-sre.html#webpage", "url": "hive-srehive-sre.html", "name": "Introduction | hive-sre", "description": "", "image": "", "inLanguage":"en-US" }</script><!-- End Schema.org --><!-- Schema.org WebSite --><script type="application/ld+json"> { "@type": "WebSite", "@id": "hive-sre/#website", "url": "hive-sre/", "name": "hive-sre Help" }</script><!-- End Schema.org --> <!-- Mermaid light/dark themes -->  <link rel="stylesheet" type="text/css" href="mermaid.css">  </head>     <body data-id="hive-sre" data-main-title="Introduction" data-article-props="{&quot;seeAlsoStyle&quot;:&quot;links&quot;}"  data-template="article"  data-breadcrumbs=""  >   <div class="wrapper"><main class="panel _main"><header class="panel__header"><div class="container"><h3>hive-sre  Help</h3><div class="panel-trigger"></div></div></header><section class="panel__content"><div class="container"><article class="article" data-shortcut-switcher="inactive"><h1 data-toc="hive-sre"  id="hive-sre.md"  >Introduction</h1>  <p id="7dd75668_47060">The <code class="code" id="7dd75668_47061">hive-sre</code> application was designed to help with the analysis of Hive Metastore and HDFS data.</p><p id="7dd75668_47062">The <a href="hive-sre-u3.html" id="7dd75668_47063" data-tooltip="The u3 sub-command is a process that is used to review 'Hive 1/2' environments for Hive3 upgrade planning."  >u3</a> sub-command is used mainly during the pre-planning phase of a major environment upgrade (HDP-&gt;CDP,CDH-&gt;CDP) to understand the scope of changes needed for CDP.</p><p id="7dd75668_47064">The <a href="hive-sre-sre.html" id="7dd75668_47065" data-tooltip="The sre sub-command is used to find potential 'Hive' performance issues caused by small files and excessive partitions."  >sre</a> sub-command is used to run a series of checks against the Hive Metastore and HDFS data to identify potential issues that would affect query/system performance and stability.</p><p id="7dd75668_47066">It is a Java application that connects directly to the Hive Metastore RDBMS and executes queries to gather information about the Hive Metastore and compares that with HDFS data.</p><section class="chapter"><h2 id="supported-metastore-db-s" data-toc="supported-metastore-db-s">Supported Metastore DB's</h2><div class="table-wrapper" ><table class="wide" id="7dd75668_47067"  ><thead><tr class="ijRowHead" id="7dd75668_47068"><th id="7dd75668_47069"><p>Sub-Program</p></th><th id="7dd75668_47070"><p>Database</p></th><th id="7dd75668_47071"><p>Version</p></th><th id="7dd75668_47072"><p>Tested</p></th><th id="7dd75668_47073"><p>Notes</p></th></tr></thead><tbody ><tr id="7dd75668_47074"><td id="7dd75668_47075"><p><code class="code" id="7dd75668_47076">u3</code></p></td><td id="7dd75668_47077"><p>MySql</p></td><td id="7dd75668_47078"><p>5.6</p></td><td id="7dd75668_47079"><p>Limited</p></td><td id="7dd75668_47080"><p>Recommend upgrading 5.7. This is the lower MySql supported env for HDP</p></td></tr><tr id="7dd75668_47081"><td id="7dd75668_47082"></td><td id="7dd75668_47083"></td><td id="7dd75668_47084"><p>5.7</p></td><td id="7dd75668_47085"><p>Yes</p></td><td id="7dd75668_47086"></td></tr><tr id="7dd75668_47087"><td id="7dd75668_47088"></td><td id="7dd75668_47089"></td><td id="7dd75668_47090"><p>8.0</p></td><td id="7dd75668_47091"><p>No</p></td><td id="7dd75668_47092"><p>Not supported by HDP</p></td></tr><tr id="7dd75668_47093"><td id="7dd75668_47094"></td><td id="7dd75668_47095"><p>MariaDb</p></td><td id="7dd75668_47096"><p>10.1</p></td><td id="7dd75668_47097"><p>No, but should work as 10.2 does</p></td><td id="7dd75668_47098"></td></tr><tr id="7dd75668_47099"><td id="7dd75668_47100"></td><td id="7dd75668_47101"></td><td id="7dd75668_47102"><p>10.2</p></td><td id="7dd75668_47103"><p>Yes</p></td><td id="7dd75668_47104"></td></tr><tr id="7dd75668_47105"><td id="7dd75668_47106"></td><td id="7dd75668_47107"><p>Postgresql</p></td><td id="7dd75668_47108"><p>9.6</p></td><td id="7dd75668_47109"><p>No, but should work</p></td><td id="7dd75668_47110"></td></tr><tr id="7dd75668_47111"><td id="7dd75668_47112"></td><td id="7dd75668_47113"></td><td id="7dd75668_47114"><p>10</p></td><td id="7dd75668_47115"><p>Yes</p></td><td id="7dd75668_47116"><p>Field Tested, May still be a few rough edges</p></td></tr><tr id="7dd75668_47117"><td id="7dd75668_47118"></td><td id="7dd75668_47119"></td><td id="7dd75668_47120"><p>11</p></td><td id="7dd75668_47121"><p>No, but should work at 10 does</p></td><td id="7dd75668_47122"></td></tr><tr id="7dd75668_47123"><td id="7dd75668_47124"></td><td id="7dd75668_47125"><p>Oracle</p></td><td id="7dd75668_47126"><p>12</p></td><td id="7dd75668_47127"><p>Yes</p></td><td id="7dd75668_47128"><p>Field Tested, May still be a few rough edges</p></td></tr><tr id="7dd75668_47129"><td id="7dd75668_47130"><p><code class="code" id="7dd75668_47131">u3e</code></p></td><td id="7dd75668_47132"><p>MySql</p></td><td id="7dd75668_47133"><p>5.6</p></td><td id="7dd75668_47134"><p>Limited</p></td><td id="7dd75668_47135"><p>Recommend upgrading 5.7. This is the lower MySql supported env for HDP</p></td></tr><tr id="7dd75668_47136"><td id="7dd75668_47137"></td><td id="7dd75668_47138"></td><td id="7dd75668_47139"><p>5.7</p></td><td id="7dd75668_47140"><p>Yes</p></td><td id="7dd75668_47141"></td></tr><tr id="7dd75668_47142"><td id="7dd75668_47143"></td><td id="7dd75668_47144"></td><td id="7dd75668_47145"><p>8.0</p></td><td id="7dd75668_47146"><p>No</p></td><td id="7dd75668_47147"><p>Not supported by HDP</p></td></tr><tr id="7dd75668_47148"><td id="7dd75668_47149"></td><td id="7dd75668_47150"><p>MariaDb</p></td><td id="7dd75668_47151"><p>10.1</p></td><td id="7dd75668_47152"><p>No, but should work as 10.2 does</p></td><td id="7dd75668_47153"></td></tr><tr id="7dd75668_47154"><td id="7dd75668_47155"></td><td id="7dd75668_47156"></td><td id="7dd75668_47157"><p>10.2</p></td><td id="7dd75668_47158"><p>Yes</p></td><td id="7dd75668_47159"></td></tr><tr id="7dd75668_47160"><td id="7dd75668_47161"></td><td id="7dd75668_47162"><p>Postgresql</p></td><td id="7dd75668_47163"><p>*</p></td><td id="7dd75668_47164"><p>NOT YET IMPLEMENTED</p></td><td id="7dd75668_47165"></td></tr><tr id="7dd75668_47166"><td id="7dd75668_47167"></td><td id="7dd75668_47168"><p>Oracle</p></td><td id="7dd75668_47169"><p>*</p></td><td id="7dd75668_47170"><p>NOT YET IMPLEMENTED</p></td><td id="7dd75668_47171"></td></tr><tr id="7dd75668_47172"><td id="7dd75668_47173"><p><code class="code" id="7dd75668_47174">sre</code></p></td><td id="7dd75668_47175"><p>MySql</p></td><td id="7dd75668_47176"><p>5.6</p></td><td id="7dd75668_47177"><p>Limited</p></td><td id="7dd75668_47178"><p>Recommend upgrading 5.7. This is the lower MySql supported env for HDP</p></td></tr><tr id="7dd75668_47179"><td id="7dd75668_47180"></td><td id="7dd75668_47181"></td><td id="7dd75668_47182"><p>5.7</p></td><td id="7dd75668_47183"><p>Partly</p></td><td id="7dd75668_47184"><p>Some <code class="code" id="7dd75668_47185">sre</code> reports use CTE in the SQL, which isn't supported in this version. Those report will error, the other will run fine.</p></td></tr><tr id="7dd75668_47186"><td id="7dd75668_47187"></td><td id="7dd75668_47188"></td><td id="7dd75668_47189"><p>8.0</p></td><td id="7dd75668_47190"><p>No</p></td><td id="7dd75668_47191"><p>Not supported by HDP</p></td></tr><tr id="7dd75668_47192"><td id="7dd75668_47193"></td><td id="7dd75668_47194"><p>MariaDb</p></td><td id="7dd75668_47195"><p>10.1</p></td><td id="7dd75668_47196"><p>No, but should work as 10.2 does</p></td><td id="7dd75668_47197"></td></tr><tr id="7dd75668_47198"><td id="7dd75668_47199"></td><td id="7dd75668_47200"></td><td id="7dd75668_47201"><p>10.2</p></td><td id="7dd75668_47202"><p>Yes</p></td><td id="7dd75668_47203"></td></tr><tr id="7dd75668_47204"><td id="7dd75668_47205"></td><td id="7dd75668_47206"><p>Postgresql</p></td><td id="7dd75668_47207"><p>9.6</p></td><td id="7dd75668_47208"><p>No, but should work</p></td><td id="7dd75668_47209"></td></tr><tr id="7dd75668_47210"><td id="7dd75668_47211"></td><td id="7dd75668_47212"></td><td id="7dd75668_47213"><p>10</p></td><td id="7dd75668_47214"><p>Yes</p></td><td id="7dd75668_47215"><p>Field Tested, May still be a few rough edges</p></td></tr><tr id="7dd75668_47216"><td id="7dd75668_47217"></td><td id="7dd75668_47218"></td><td id="7dd75668_47219"><p>11</p></td><td id="7dd75668_47220"><p>No, but should work at 10 does</p></td><td id="7dd75668_47221"></td></tr><tr id="7dd75668_47222"><td id="7dd75668_47223"></td><td id="7dd75668_47224"><p>Oracle</p></td><td id="7dd75668_47225"><p>12</p></td><td id="7dd75668_47226"><p>Yes</p></td><td id="7dd75668_47227"><p>Field Tested, May still be a few rough edges</p></td></tr></tbody ></table ></div><p id="7dd75668_47228">Ensure you have the database appropriate driver in the <code class="code" id="7dd75668_47229">${HOME}/.hive-sre/aux_libs</code> directory.</p><p id="7dd75668_47230">I've tried to match supported DB's for HDP 2.6.5 and 3.1.x as much as I could.</p></section><section class="chapter"><h2 id="hadoop-cli" data-toc="hadoop-cli">Hadoop CLI</h2><p id="7dd75668_47231">Running <code class="code" id="7dd75668_47232">hive-sre-cli</code> on the command line is an alias to the <code class="code" id="7dd75668_47233">hadoopcli</code> application <a href="https://github.com/dstreev/hadoop-cli" id="7dd75668_47234"   data-external="true" rel="noopener noreferrer" >here</a>.</p><p id="7dd75668_47235">It is an interactive HDFS Client Command Line tool.</p></section><section class="chapter"><h2 id="ping-performance-tool" data-toc="ping-performance-tool">Ping Performance Tool</h2><p id="7dd75668_47236">Included in this application suite is a <code class="code" id="7dd75668_47237">ping</code> performance tool that you can use to measure cluster host letancy. It is a MapReduce application that uses a list of hosts and will <code class="code" id="7dd75668_47238">ping</code> those hosts from the MR Map Task and record the results to HDFS.</p><p id="7dd75668_47239">The MR program take a few options:</p><div class="code-block" data-lang="none"         >
usage: hadoop jar &lt;jar-file&gt; com.cloudera.utils.mapreduce.MRPingTool -d &lt;output-dir&gt; -hl &lt;hdfs_host_list_file&gt; [-c &lt;count&gt;] [-m &lt;num_of_mappers&gt;]
 -c,--count &lt;arg&gt;        Ping Count (The number of iterations we'll run
                         ping).  Each ping request makes 5 pings.
                         So if this value is 3, we'll do 3 sets of 5 pings
                         (15 total). Default 5
 -d,--directory &lt;arg&gt;    Output Directory [REQUIRED]
 -h,--help               Help
 -hl,--host-list &lt;arg&gt;   The host list file on HDFS. A text file with a
                         FQHN (full qualified host name) per
                         line.[REQUIRED]
 -m,--mappers &lt;arg&gt;      Number of Mappers.  To get coverage, should be
                         more than the compute node count.  But no
                         guarantee of even distribution, so best to over
                         subscribe. Default 2
</div><section class="chapter"><h3 id="tested-os-s" data-toc="tested-os-s">Tested OS's</h3><p id="7dd75668_47241">CentOS 7.6 (ping)</p><p id="7dd75668_47242">The ping output is parsed by the application and other OS/versions may yield different output, which we've not (yet) setup parsing for.</p></section><section class="chapter"><h3 id="let-s-assume" data-toc="let-s-assume">Let's assume:</h3><ul class="list _ul" id="7dd75668_47243"    ><li class="list__item" id="7dd75668_47244"><p>You've downloaded the Hive <a href="https://github.com/cloudera-labs/hive-sre/tree/main/src/main/resources/ping" id="7dd75668_47245"   data-external="true" rel="noopener noreferrer" >setup/ingest/eval scripts</a></p></li><li class="list__item" id="7dd75668_47246"><p>This has been tested again CentOS 7.</p></li><li class="list__item" id="7dd75668_47247"><p>The user running the MR job has rights in each compute node to run <code class="code" id="7dd75668_47248">ping</code>.</p></li><li class="list__item" id="7dd75668_47249"><p>That <code class="code" id="7dd75668_47250">ping</code> is allowed on the network and not blocked between hosts.</p></li><li class="list__item" id="7dd75668_47251"><p>The MR Job is run with the right user credentials and from an Edgenode configured for the target cluster. </p><ul class="list _ul" id="7dd75668_47252"    ><li class="list__item" id="7dd75668_47253"><p>We need the hadoop MR libs to submit the job.</p></li></ul></li><li class="list__item" id="7dd75668_47254"><p>The user running the job has ACL's that allow them to write to the EXTERNAL db location you create with <code class="code" id="7dd75668_47255">ping_ddl.sql</code>.</p></li><li class="list__item" id="7dd75668_47256"><p>Build a 'host list' file with ALL the FQHN (fully qualified hostnames) in the cluster that you want to test. </p><ul class="list _ul" id="7dd75668_47257"    ><li class="list__item" id="7dd75668_47258"><p>This is a text file with a single host FQHN per line. Similar to /etc/hosts.</p></li><li class="list__item" id="7dd75668_47259"><p>Place the file (we'll use the name <code class="code" id="7dd75668_47260">host_list.txt</code>) in your HDFS home directory.</p></li></ul></li><li class="list__item" id="7dd75668_47261"><p>We are using the standard EXTERNAL and MANAGED Warehouse locations on HDFS</p></li><li class="list__item" id="7dd75668_47262"><p>PING_DB = ping_perf</p></li><li class="list__item" id="7dd75668_47263"><p>BATCH_ID = 2022-10-22_01</p></li></ul></section><section class="chapter"><h3 id="procedure" data-toc="procedure">Procedure</h3><ol class="list _decimal" id="7dd75668_47264"  type="1"  ><li class="list__item" id="7dd75668_47265"><p>Run DDL Scripts in Beeline </p><ol class="list _decimal" id="7dd75668_47266"  type="1"  start="2"><li class="list__item" id="7dd75668_47267"><p><code class="code" id="7dd75668_47268">beeline -f ping_ddl.sql --hivevar PING_DB=ping_perf</code></p></li></ol></li><li class="list__item" id="7dd75668_47269"><p>Run MR Job, using the expected Partition Directory of the <code class="code" id="7dd75668_47270">raw</code> table as the output. The <code class="code" id="7dd75668_47271">-m</code> parameter controls the number of 'mappers' created. The intent is to get a map task on every compute node in the cluster. To do that, with perfect distribution (unlikely), you need at least as many mappers as there are compute nodes. We recommend 2-3x that incase some nodes get doubled up. There's no way to ensure every host runs a task, hence the over subscription here. Use the eval report to determine where the gaps where (if any) and run again. </p><ol class="list _decimal" id="7dd75668_47272"  type="1"  start="4"><li class="list__item" id="7dd75668_47273"><p><code class="code" id="7dd75668_47274">hadoop jar /usr/local/hive-sre/lib/hive-sre-shaded.jar com.cloudera.utils.mapreduce.MRPingTool -m 40 -c 3 -hl host_list.txt -d /warehouse/tablespace/external/hive/ping_perf.db/raw/batch_id=2022-10-21_01</code></p></li></ol></li><li class="list__item" id="7dd75668_47275"><p>Run the Ingest script in <code class="code" id="7dd75668_47276">beeline</code></p><ol class="list _decimal" id="7dd75668_47277"  type="1"  start="6"><li class="list__item" id="7dd75668_47278"><p><code class="code" id="7dd75668_47279">beeline -f ping_ingest.sql --hivevar PING_DB=ping_perf --hivevar BATCH_ID=2022-10-21_01</code></p></li></ol></li><li class="list__item" id="7dd75668_47280"><p>Run the <a href="https://github.com/cloudera-labs/hive-sre/blob/main/src/main/resources/ping/ping_eval.sql" id="7dd75668_47281"   data-external="true" rel="noopener noreferrer" >eval scripts</a> in <code class="code" id="7dd75668_47282">beeline --hivevar PING_DB=ping_perf --hivevar BATCH_ID=2022-10-21_01</code></p></li></ol></section></section><div class="last-modified"> Last modified: 06 November 2023</div><div data-feedback-placeholder="true"></div><div class="navigation-links _bottom">   <a class="navigation-links__next" href="hive-sre-sub-commands.html">Sub-Commands</a>  </div></article><div id="disqus_thread"></div></div></section></main></div>  <script src="https://resources.jetbrains.com/writerside/apidoc/6.1.5-b176/app.js"></script></body></html>