<!DOCTYPE html SYSTEM "about:legacy-compat"><html lang="en-US" data-colors-preset="contrast" data-primary-color="#307FFF"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta charset="UTF-8"><meta name="robots" content="noindex">  <meta name="built-on" content="2023-11-07T08:04:35.889511"><meta name="build-number" content="${buildNumber}">       <title>Introduction | hive-sre</title><script id="virtual-toc-data" type="application/json">[{"id":"supported-metastore-db-s","level":0,"title":"Supported Metastore DB\u0027s","anchor":"#supported-metastore-db-s"},{"id":"hadoop-cli","level":0,"title":"Hadoop CLI","anchor":"#hadoop-cli"},{"id":"ping-performance-tool","level":0,"title":"Ping Performance Tool","anchor":"#ping-performance-tool"}]</script><script id="topic-shortcuts" type="application/json"></script><link href="https://resources.jetbrains.com/writerside/apidoc/6.1.5-b176/app.css" rel="stylesheet">   <link rel="apple-touch-icon" sizes="180x180" href="https://jetbrains.com/apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="https://jetbrains.com/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="https://jetbrains.com/favicon-16x16.png"><link rel="manifest" href="https://jetbrains.com/site.webmanifest"><link rel="mask-icon" href="https://jetbrains.com/safari-pinned-tab.svg" color="#000000"><meta name="msapplication-TileColor" content="#000000"/><meta name="msapplication-TileImage" content="https://resources.jetbrains.com/storage/ui/favicons/mstile-144x144.png"/><meta name="msapplication-square70x70logo" content="https://resources.jetbrains.com/storage/ui/favicons/mstile-70x70.png"/><meta name="msapplication-square150x150logo" content="https://resources.jetbrains.com/storage/ui/favicons/mstile-150x150.png"/><meta name="msapplication-wide310x150logo" content="https://resources.jetbrains.com/storage/ui/favicons/mstile-310x150.png"/><meta name="msapplication-square310x310logo" content="https://resources.jetbrains.com/storage/ui/favicons/mstile-310x310.png"/>  <meta name="image" content=""><!-- Open Graph --><meta property="og:title" content="Introduction | hive-sre"/><meta property="og:description" content=""/><meta property="og:image" content=""/><meta property="og:site_name" content="hive-sre Help"/><meta property="og:type" content="website"/><meta property="og:locale" content="en_US"/><meta property="og:url" content="hive-srehive-sre.html"/><!-- End Open Graph --><!-- Twitter Card --><meta name="twitter:card" content="summary_large_image"><meta name="twitter:site" content=""><meta name="twitter:title" content="Introduction | hive-sre"><meta name="twitter:description" content=""><meta name="twitter:creator" content=""><meta name="twitter:image:src" content=""><!-- End Twitter Card --><!-- Schema.org WebPage --><script type="application/ld+json"> { "@context": "http://schema.org", "@type": "WebPage", "@id": "hive-srehive-sre.html#webpage", "url": "hive-srehive-sre.html", "name": "Introduction | hive-sre", "description": "", "image": "", "inLanguage":"en-US" }</script><!-- End Schema.org --><!-- Schema.org WebSite --><script type="application/ld+json"> { "@type": "WebSite", "@id": "hive-sre/#website", "url": "hive-sre/", "name": "hive-sre Help" }</script><!-- End Schema.org --> <!-- Mermaid light/dark themes -->  <link rel="stylesheet" type="text/css" href="mermaid.css">  </head>     <body data-id="hive-sre" data-main-title="Introduction" data-article-props="{&quot;seeAlsoStyle&quot;:&quot;links&quot;}"  data-template="article"  data-breadcrumbs=""  >   <div class="wrapper"><main class="panel _main"><header class="panel__header"><div class="container"><h3>hive-sre  Help</h3><div class="panel-trigger"></div></div></header><section class="panel__content"><div class="container"><article class="article" data-shortcut-switcher="inactive"><h1 data-toc="hive-sre"  id="hive-sre.md"  >Introduction</h1>  <p id="7dd75668_51301">The <code class="code" id="7dd75668_51302">hive-sre</code> application was designed to help with the analysis of Hive Metastore and HDFS data.</p><p id="7dd75668_51303">The <a href="hive-sre-u3.html" id="7dd75668_51304" data-tooltip="The u3 sub-command is a process that is used to review 'Hive 1/2' environments for Hive3 upgrade planning."  >u3</a> sub-command is used mainly during the pre-planning phase of a major environment upgrade (HDP-&gt;CDP,CDH-&gt;CDP) to understand the scope of changes needed for CDP.</p><p id="7dd75668_51305">The <a href="hive-sre-sre.html" id="7dd75668_51306" data-tooltip="The sre sub-command is used to find potential 'Hive' performance issues caused by small files and excessive partitions."  >sre</a> sub-command is used to run a series of checks against the Hive Metastore and HDFS data to identify potential issues that would affect query/system performance and stability.</p><p id="7dd75668_51307">It is a Java application that connects directly to the Hive Metastore RDBMS and executes queries to gather information about the Hive Metastore and compares that with HDFS data.</p><section class="chapter"><h2 id="supported-metastore-db-s" data-toc="supported-metastore-db-s">Supported Metastore DB's</h2><div class="table-wrapper" ><table class="wide" id="7dd75668_51308"  ><thead><tr class="ijRowHead" id="7dd75668_51309"><th id="7dd75668_51310"><p>Sub-Program</p></th><th id="7dd75668_51311"><p>Database</p></th><th id="7dd75668_51312"><p>Version</p></th><th id="7dd75668_51313"><p>Tested</p></th><th id="7dd75668_51314"><p>Notes</p></th></tr></thead><tbody ><tr id="7dd75668_51315"><td id="7dd75668_51316"><p><code class="code" id="7dd75668_51317">u3</code></p></td><td id="7dd75668_51318"><p>MySql</p></td><td id="7dd75668_51319"><p>5.6</p></td><td id="7dd75668_51320"><p>Limited</p></td><td id="7dd75668_51321"><p>Recommend upgrading 5.7. This is the lower MySql supported env for HDP</p></td></tr><tr id="7dd75668_51322"><td id="7dd75668_51323"></td><td id="7dd75668_51324"></td><td id="7dd75668_51325"><p>5.7</p></td><td id="7dd75668_51326"><p>Yes</p></td><td id="7dd75668_51327"></td></tr><tr id="7dd75668_51328"><td id="7dd75668_51329"></td><td id="7dd75668_51330"></td><td id="7dd75668_51331"><p>8.0</p></td><td id="7dd75668_51332"><p>No</p></td><td id="7dd75668_51333"><p>Not supported by HDP</p></td></tr><tr id="7dd75668_51334"><td id="7dd75668_51335"></td><td id="7dd75668_51336"><p>MariaDb</p></td><td id="7dd75668_51337"><p>10.1</p></td><td id="7dd75668_51338"><p>No, but should work as 10.2 does</p></td><td id="7dd75668_51339"></td></tr><tr id="7dd75668_51340"><td id="7dd75668_51341"></td><td id="7dd75668_51342"></td><td id="7dd75668_51343"><p>10.2</p></td><td id="7dd75668_51344"><p>Yes</p></td><td id="7dd75668_51345"></td></tr><tr id="7dd75668_51346"><td id="7dd75668_51347"></td><td id="7dd75668_51348"><p>Postgresql</p></td><td id="7dd75668_51349"><p>9.6</p></td><td id="7dd75668_51350"><p>No, but should work</p></td><td id="7dd75668_51351"></td></tr><tr id="7dd75668_51352"><td id="7dd75668_51353"></td><td id="7dd75668_51354"></td><td id="7dd75668_51355"><p>10</p></td><td id="7dd75668_51356"><p>Yes</p></td><td id="7dd75668_51357"><p>Field Tested, May still be a few rough edges</p></td></tr><tr id="7dd75668_51358"><td id="7dd75668_51359"></td><td id="7dd75668_51360"></td><td id="7dd75668_51361"><p>11</p></td><td id="7dd75668_51362"><p>No, but should work at 10 does</p></td><td id="7dd75668_51363"></td></tr><tr id="7dd75668_51364"><td id="7dd75668_51365"></td><td id="7dd75668_51366"><p>Oracle</p></td><td id="7dd75668_51367"><p>12</p></td><td id="7dd75668_51368"><p>Yes</p></td><td id="7dd75668_51369"><p>Field Tested, May still be a few rough edges</p></td></tr><tr id="7dd75668_51370"><td id="7dd75668_51371"><p><code class="code" id="7dd75668_51372">u3e</code></p></td><td id="7dd75668_51373"><p>MySql</p></td><td id="7dd75668_51374"><p>5.6</p></td><td id="7dd75668_51375"><p>Limited</p></td><td id="7dd75668_51376"><p>Recommend upgrading 5.7. This is the lower MySql supported env for HDP</p></td></tr><tr id="7dd75668_51377"><td id="7dd75668_51378"></td><td id="7dd75668_51379"></td><td id="7dd75668_51380"><p>5.7</p></td><td id="7dd75668_51381"><p>Yes</p></td><td id="7dd75668_51382"></td></tr><tr id="7dd75668_51383"><td id="7dd75668_51384"></td><td id="7dd75668_51385"></td><td id="7dd75668_51386"><p>8.0</p></td><td id="7dd75668_51387"><p>No</p></td><td id="7dd75668_51388"><p>Not supported by HDP</p></td></tr><tr id="7dd75668_51389"><td id="7dd75668_51390"></td><td id="7dd75668_51391"><p>MariaDb</p></td><td id="7dd75668_51392"><p>10.1</p></td><td id="7dd75668_51393"><p>No, but should work as 10.2 does</p></td><td id="7dd75668_51394"></td></tr><tr id="7dd75668_51395"><td id="7dd75668_51396"></td><td id="7dd75668_51397"></td><td id="7dd75668_51398"><p>10.2</p></td><td id="7dd75668_51399"><p>Yes</p></td><td id="7dd75668_51400"></td></tr><tr id="7dd75668_51401"><td id="7dd75668_51402"></td><td id="7dd75668_51403"><p>Postgresql</p></td><td id="7dd75668_51404"><p>*</p></td><td id="7dd75668_51405"><p>NOT YET IMPLEMENTED</p></td><td id="7dd75668_51406"></td></tr><tr id="7dd75668_51407"><td id="7dd75668_51408"></td><td id="7dd75668_51409"><p>Oracle</p></td><td id="7dd75668_51410"><p>*</p></td><td id="7dd75668_51411"><p>NOT YET IMPLEMENTED</p></td><td id="7dd75668_51412"></td></tr><tr id="7dd75668_51413"><td id="7dd75668_51414"><p><code class="code" id="7dd75668_51415">sre</code></p></td><td id="7dd75668_51416"><p>MySql</p></td><td id="7dd75668_51417"><p>5.6</p></td><td id="7dd75668_51418"><p>Limited</p></td><td id="7dd75668_51419"><p>Recommend upgrading 5.7. This is the lower MySql supported env for HDP</p></td></tr><tr id="7dd75668_51420"><td id="7dd75668_51421"></td><td id="7dd75668_51422"></td><td id="7dd75668_51423"><p>5.7</p></td><td id="7dd75668_51424"><p>Partly</p></td><td id="7dd75668_51425"><p>Some <code class="code" id="7dd75668_51426">sre</code> reports use CTE in the SQL, which isn't supported in this version. Those report will error, the other will run fine.</p></td></tr><tr id="7dd75668_51427"><td id="7dd75668_51428"></td><td id="7dd75668_51429"></td><td id="7dd75668_51430"><p>8.0</p></td><td id="7dd75668_51431"><p>No</p></td><td id="7dd75668_51432"><p>Not supported by HDP</p></td></tr><tr id="7dd75668_51433"><td id="7dd75668_51434"></td><td id="7dd75668_51435"><p>MariaDb</p></td><td id="7dd75668_51436"><p>10.1</p></td><td id="7dd75668_51437"><p>No, but should work as 10.2 does</p></td><td id="7dd75668_51438"></td></tr><tr id="7dd75668_51439"><td id="7dd75668_51440"></td><td id="7dd75668_51441"></td><td id="7dd75668_51442"><p>10.2</p></td><td id="7dd75668_51443"><p>Yes</p></td><td id="7dd75668_51444"></td></tr><tr id="7dd75668_51445"><td id="7dd75668_51446"></td><td id="7dd75668_51447"><p>Postgresql</p></td><td id="7dd75668_51448"><p>9.6</p></td><td id="7dd75668_51449"><p>No, but should work</p></td><td id="7dd75668_51450"></td></tr><tr id="7dd75668_51451"><td id="7dd75668_51452"></td><td id="7dd75668_51453"></td><td id="7dd75668_51454"><p>10</p></td><td id="7dd75668_51455"><p>Yes</p></td><td id="7dd75668_51456"><p>Field Tested, May still be a few rough edges</p></td></tr><tr id="7dd75668_51457"><td id="7dd75668_51458"></td><td id="7dd75668_51459"></td><td id="7dd75668_51460"><p>11</p></td><td id="7dd75668_51461"><p>No, but should work at 10 does</p></td><td id="7dd75668_51462"></td></tr><tr id="7dd75668_51463"><td id="7dd75668_51464"></td><td id="7dd75668_51465"><p>Oracle</p></td><td id="7dd75668_51466"><p>12</p></td><td id="7dd75668_51467"><p>Yes</p></td><td id="7dd75668_51468"><p>Field Tested, May still be a few rough edges</p></td></tr></tbody ></table ></div><p id="7dd75668_51469">Ensure you have the database appropriate driver in the <code class="code" id="7dd75668_51470">${HOME}/.hive-sre/aux_libs</code> directory.</p><p id="7dd75668_51471">I've tried to match supported DB's for HDP 2.6.5 and 3.1.x as much as I could.</p></section><section class="chapter"><h2 id="hadoop-cli" data-toc="hadoop-cli">Hadoop CLI</h2><p id="7dd75668_51472">Running <code class="code" id="7dd75668_51473">hive-sre-cli</code> on the command line is an alias to the <code class="code" id="7dd75668_51474">hadoopcli</code> application <a href="https://github.com/dstreev/hadoop-cli" id="7dd75668_51475"   data-external="true" rel="noopener noreferrer" >here</a>.</p><p id="7dd75668_51476">It is an interactive HDFS Client Command Line tool.</p></section><section class="chapter"><h2 id="ping-performance-tool" data-toc="ping-performance-tool">Ping Performance Tool</h2><p id="7dd75668_51477">Included in this application suite is a <code class="code" id="7dd75668_51478">ping</code> performance tool that you can use to measure cluster host letancy. It is a MapReduce application that uses a list of hosts and will <code class="code" id="7dd75668_51479">ping</code> those hosts from the MR Map Task and record the results to HDFS.</p><p id="7dd75668_51480">The MR program take a few options:</p><div class="code-block" data-lang="none"         >
usage: hadoop jar &lt;jar-file&gt; com.cloudera.utils.mapreduce.MRPingTool -d &lt;output-dir&gt; -hl &lt;hdfs_host_list_file&gt; [-c &lt;count&gt;] [-m &lt;num_of_mappers&gt;]
 -c,--count &lt;arg&gt;        Ping Count (The number of iterations we'll run
                         ping).  Each ping request makes 5 pings.
                         So if this value is 3, we'll do 3 sets of 5 pings
                         (15 total). Default 5
 -d,--directory &lt;arg&gt;    Output Directory [REQUIRED]
 -h,--help               Help
 -hl,--host-list &lt;arg&gt;   The host list file on HDFS. A text file with a
                         FQHN (full qualified host name) per
                         line.[REQUIRED]
 -m,--mappers &lt;arg&gt;      Number of Mappers.  To get coverage, should be
                         more than the compute node count.  But no
                         guarantee of even distribution, so best to over
                         subscribe. Default 2
</div><section class="chapter"><h3 id="tested-os-s" data-toc="tested-os-s">Tested OS's</h3><p id="7dd75668_51482">CentOS 7.6 (ping)</p><p id="7dd75668_51483">The ping output is parsed by the application and other OS/versions may yield different output, which we've not (yet) setup parsing for.</p></section><section class="chapter"><h3 id="let-s-assume" data-toc="let-s-assume">Let's assume:</h3><ul class="list _ul" id="7dd75668_51484"    ><li class="list__item" id="7dd75668_51485"><p>You've downloaded the Hive <a href="https://github.com/cloudera-labs/hive-sre/tree/main/src/main/resources/ping" id="7dd75668_51486"   data-external="true" rel="noopener noreferrer" >setup/ingest/eval scripts</a></p></li><li class="list__item" id="7dd75668_51487"><p>This has been tested again CentOS 7.</p></li><li class="list__item" id="7dd75668_51488"><p>The user running the MR job has rights in each compute node to run <code class="code" id="7dd75668_51489">ping</code>.</p></li><li class="list__item" id="7dd75668_51490"><p>That <code class="code" id="7dd75668_51491">ping</code> is allowed on the network and not blocked between hosts.</p></li><li class="list__item" id="7dd75668_51492"><p>The MR Job is run with the right user credentials and from an Edgenode configured for the target cluster. </p><ul class="list _ul" id="7dd75668_51493"    ><li class="list__item" id="7dd75668_51494"><p>We need the hadoop MR libs to submit the job.</p></li></ul></li><li class="list__item" id="7dd75668_51495"><p>The user running the job has ACL's that allow them to write to the EXTERNAL db location you create with <code class="code" id="7dd75668_51496">ping_ddl.sql</code>.</p></li><li class="list__item" id="7dd75668_51497"><p>Build a 'host list' file with ALL the FQHN (fully qualified hostnames) in the cluster that you want to test. </p><ul class="list _ul" id="7dd75668_51498"    ><li class="list__item" id="7dd75668_51499"><p>This is a text file with a single host FQHN per line. Similar to /etc/hosts.</p></li><li class="list__item" id="7dd75668_51500"><p>Place the file (we'll use the name <code class="code" id="7dd75668_51501">host_list.txt</code>) in your HDFS home directory.</p></li></ul></li><li class="list__item" id="7dd75668_51502"><p>We are using the standard EXTERNAL and MANAGED Warehouse locations on HDFS</p></li><li class="list__item" id="7dd75668_51503"><p>PING_DB = ping_perf</p></li><li class="list__item" id="7dd75668_51504"><p>BATCH_ID = 2022-10-22_01</p></li></ul></section><section class="chapter"><h3 id="procedure" data-toc="procedure">Procedure</h3><ol class="list _decimal" id="7dd75668_51505"  type="1"  ><li class="list__item" id="7dd75668_51506"><p>Run DDL Scripts in Beeline </p><ol class="list _decimal" id="7dd75668_51507"  type="1"  start="2"><li class="list__item" id="7dd75668_51508"><p><code class="code" id="7dd75668_51509">beeline -f ping_ddl.sql --hivevar PING_DB=ping_perf</code></p></li></ol></li><li class="list__item" id="7dd75668_51510"><p>Run MR Job, using the expected Partition Directory of the <code class="code" id="7dd75668_51511">raw</code> table as the output. The <code class="code" id="7dd75668_51512">-m</code> parameter controls the number of 'mappers' created. The intent is to get a map task on every compute node in the cluster. To do that, with perfect distribution (unlikely), you need at least as many mappers as there are compute nodes. We recommend 2-3x that incase some nodes get doubled up. There's no way to ensure every host runs a task, hence the over subscription here. Use the eval report to determine where the gaps where (if any) and run again. </p><ol class="list _decimal" id="7dd75668_51513"  type="1"  start="4"><li class="list__item" id="7dd75668_51514"><p><code class="code" id="7dd75668_51515">hadoop jar /usr/local/hive-sre/lib/hive-sre-shaded.jar com.cloudera.utils.mapreduce.MRPingTool -m 40 -c 3 -hl host_list.txt -d /warehouse/tablespace/external/hive/ping_perf.db/raw/batch_id=2022-10-21_01</code></p></li></ol></li><li class="list__item" id="7dd75668_51516"><p>Run the Ingest script in <code class="code" id="7dd75668_51517">beeline</code></p><ol class="list _decimal" id="7dd75668_51518"  type="1"  start="6"><li class="list__item" id="7dd75668_51519"><p><code class="code" id="7dd75668_51520">beeline -f ping_ingest.sql --hivevar PING_DB=ping_perf --hivevar BATCH_ID=2022-10-21_01</code></p></li></ol></li><li class="list__item" id="7dd75668_51521"><p>Run the <a href="https://github.com/cloudera-labs/hive-sre/blob/main/src/main/resources/ping/ping_eval.sql" id="7dd75668_51522"   data-external="true" rel="noopener noreferrer" >eval scripts</a> in <code class="code" id="7dd75668_51523">beeline --hivevar PING_DB=ping_perf --hivevar BATCH_ID=2022-10-21_01</code></p></li></ol></section></section><div class="last-modified"> Last modified: 07 November 2023</div><div data-feedback-placeholder="true"></div><div class="navigation-links _bottom">   <a class="navigation-links__next" href="hive-sre-sub-commands.html">Sub-Commands</a>  </div></article><div id="disqus_thread"></div></div></section></main></div>  <script src="https://resources.jetbrains.com/writerside/apidoc/6.1.5-b176/app.js"></script></body></html>