<!DOCTYPE html SYSTEM "about:legacy-compat"><html lang="en-US" data-colors-preset="contrast" data-primary-color="#307FFF"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta charset="UTF-8"><meta name="robots" content="noindex">  <meta name="built-on" content="2023-11-06T15:26:13.593404"><meta name="build-number" content="${buildNumber}">       <title>Introduction | hive-sre</title><script id="virtual-toc-data" type="application/json">[{"id":"supported-metastore-db-s","level":0,"title":"Supported Metastore DB\u0027s","anchor":"#supported-metastore-db-s"},{"id":"hadoop-cli","level":0,"title":"Hadoop CLI","anchor":"#hadoop-cli"},{"id":"ping-performance-tool","level":0,"title":"Ping Performance Tool","anchor":"#ping-performance-tool"}]</script><script id="topic-shortcuts" type="application/json"></script><link href="https://resources.jetbrains.com/writerside/apidoc/6.1.5-b176/app.css" rel="stylesheet">   <link rel="apple-touch-icon" sizes="180x180" href="https://jetbrains.com/apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="https://jetbrains.com/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="https://jetbrains.com/favicon-16x16.png"><link rel="manifest" href="https://jetbrains.com/site.webmanifest"><link rel="mask-icon" href="https://jetbrains.com/safari-pinned-tab.svg" color="#000000"><meta name="msapplication-TileColor" content="#000000"/><meta name="msapplication-TileImage" content="https://resources.jetbrains.com/storage/ui/favicons/mstile-144x144.png"/><meta name="msapplication-square70x70logo" content="https://resources.jetbrains.com/storage/ui/favicons/mstile-70x70.png"/><meta name="msapplication-square150x150logo" content="https://resources.jetbrains.com/storage/ui/favicons/mstile-150x150.png"/><meta name="msapplication-wide310x150logo" content="https://resources.jetbrains.com/storage/ui/favicons/mstile-310x150.png"/><meta name="msapplication-square310x310logo" content="https://resources.jetbrains.com/storage/ui/favicons/mstile-310x310.png"/>  <meta name="image" content=""><!-- Open Graph --><meta property="og:title" content="Introduction | hive-sre"/><meta property="og:description" content=""/><meta property="og:image" content=""/><meta property="og:site_name" content="hive-sre Help"/><meta property="og:type" content="website"/><meta property="og:locale" content="en_US"/><meta property="og:url" content="hive-srehive-sre.html"/><!-- End Open Graph --><!-- Twitter Card --><meta name="twitter:card" content="summary_large_image"><meta name="twitter:site" content=""><meta name="twitter:title" content="Introduction | hive-sre"><meta name="twitter:description" content=""><meta name="twitter:creator" content=""><meta name="twitter:image:src" content=""><!-- End Twitter Card --><!-- Schema.org WebPage --><script type="application/ld+json"> { "@context": "http://schema.org", "@type": "WebPage", "@id": "hive-srehive-sre.html#webpage", "url": "hive-srehive-sre.html", "name": "Introduction | hive-sre", "description": "", "image": "", "inLanguage":"en-US" }</script><!-- End Schema.org --><!-- Schema.org WebSite --><script type="application/ld+json"> { "@type": "WebSite", "@id": "hive-sre/#website", "url": "hive-sre/", "name": "hive-sre Help" }</script><!-- End Schema.org --> <!-- Mermaid light/dark themes -->  <link rel="stylesheet" type="text/css" href="mermaid.css">  </head>     <body data-id="hive-sre" data-main-title="Introduction" data-article-props="{&quot;seeAlsoStyle&quot;:&quot;links&quot;}"  data-template="article"  data-breadcrumbs=""  >   <div class="wrapper"><main class="panel _main"><header class="panel__header"><div class="container"><h3>hive-sre  Help</h3><div class="panel-trigger"></div></div></header><section class="panel__content"><div class="container"><article class="article" data-shortcut-switcher="inactive"><h1 data-toc="hive-sre"  id="hive-sre.md"  >Introduction</h1>  <p id="7dd75668_50627">The <code class="code" id="7dd75668_50628">hive-sre</code> application was designed to help with the analysis of Hive Metastore and HDFS data.</p><p id="7dd75668_50629">The <a href="hive-sre-u3.html" id="7dd75668_50630" data-tooltip="The u3 sub-command is a process that is used to review 'Hive 1/2' environments for Hive3 upgrade planning."  >u3</a> sub-command is used mainly during the pre-planning phase of a major environment upgrade (HDP-&gt;CDP,CDH-&gt;CDP) to understand the scope of changes needed for CDP.</p><p id="7dd75668_50631">The <a href="hive-sre-sre.html" id="7dd75668_50632" data-tooltip="The sre sub-command is used to find potential 'Hive' performance issues caused by small files and excessive partitions."  >sre</a> sub-command is used to run a series of checks against the Hive Metastore and HDFS data to identify potential issues that would affect query/system performance and stability.</p><p id="7dd75668_50633">It is a Java application that connects directly to the Hive Metastore RDBMS and executes queries to gather information about the Hive Metastore and compares that with HDFS data.</p><section class="chapter"><h2 id="supported-metastore-db-s" data-toc="supported-metastore-db-s">Supported Metastore DB's</h2><div class="table-wrapper" ><table class="wide" id="7dd75668_50634"  ><thead><tr class="ijRowHead" id="7dd75668_50635"><th id="7dd75668_50636"><p>Sub-Program</p></th><th id="7dd75668_50637"><p>Database</p></th><th id="7dd75668_50638"><p>Version</p></th><th id="7dd75668_50639"><p>Tested</p></th><th id="7dd75668_50640"><p>Notes</p></th></tr></thead><tbody ><tr id="7dd75668_50641"><td id="7dd75668_50642"><p><code class="code" id="7dd75668_50643">u3</code></p></td><td id="7dd75668_50644"><p>MySql</p></td><td id="7dd75668_50645"><p>5.6</p></td><td id="7dd75668_50646"><p>Limited</p></td><td id="7dd75668_50647"><p>Recommend upgrading 5.7. This is the lower MySql supported env for HDP</p></td></tr><tr id="7dd75668_50648"><td id="7dd75668_50649"></td><td id="7dd75668_50650"></td><td id="7dd75668_50651"><p>5.7</p></td><td id="7dd75668_50652"><p>Yes</p></td><td id="7dd75668_50653"></td></tr><tr id="7dd75668_50654"><td id="7dd75668_50655"></td><td id="7dd75668_50656"></td><td id="7dd75668_50657"><p>8.0</p></td><td id="7dd75668_50658"><p>No</p></td><td id="7dd75668_50659"><p>Not supported by HDP</p></td></tr><tr id="7dd75668_50660"><td id="7dd75668_50661"></td><td id="7dd75668_50662"><p>MariaDb</p></td><td id="7dd75668_50663"><p>10.1</p></td><td id="7dd75668_50664"><p>No, but should work as 10.2 does</p></td><td id="7dd75668_50665"></td></tr><tr id="7dd75668_50666"><td id="7dd75668_50667"></td><td id="7dd75668_50668"></td><td id="7dd75668_50669"><p>10.2</p></td><td id="7dd75668_50670"><p>Yes</p></td><td id="7dd75668_50671"></td></tr><tr id="7dd75668_50672"><td id="7dd75668_50673"></td><td id="7dd75668_50674"><p>Postgresql</p></td><td id="7dd75668_50675"><p>9.6</p></td><td id="7dd75668_50676"><p>No, but should work</p></td><td id="7dd75668_50677"></td></tr><tr id="7dd75668_50678"><td id="7dd75668_50679"></td><td id="7dd75668_50680"></td><td id="7dd75668_50681"><p>10</p></td><td id="7dd75668_50682"><p>Yes</p></td><td id="7dd75668_50683"><p>Field Tested, May still be a few rough edges</p></td></tr><tr id="7dd75668_50684"><td id="7dd75668_50685"></td><td id="7dd75668_50686"></td><td id="7dd75668_50687"><p>11</p></td><td id="7dd75668_50688"><p>No, but should work at 10 does</p></td><td id="7dd75668_50689"></td></tr><tr id="7dd75668_50690"><td id="7dd75668_50691"></td><td id="7dd75668_50692"><p>Oracle</p></td><td id="7dd75668_50693"><p>12</p></td><td id="7dd75668_50694"><p>Yes</p></td><td id="7dd75668_50695"><p>Field Tested, May still be a few rough edges</p></td></tr><tr id="7dd75668_50696"><td id="7dd75668_50697"><p><code class="code" id="7dd75668_50698">u3e</code></p></td><td id="7dd75668_50699"><p>MySql</p></td><td id="7dd75668_50700"><p>5.6</p></td><td id="7dd75668_50701"><p>Limited</p></td><td id="7dd75668_50702"><p>Recommend upgrading 5.7. This is the lower MySql supported env for HDP</p></td></tr><tr id="7dd75668_50703"><td id="7dd75668_50704"></td><td id="7dd75668_50705"></td><td id="7dd75668_50706"><p>5.7</p></td><td id="7dd75668_50707"><p>Yes</p></td><td id="7dd75668_50708"></td></tr><tr id="7dd75668_50709"><td id="7dd75668_50710"></td><td id="7dd75668_50711"></td><td id="7dd75668_50712"><p>8.0</p></td><td id="7dd75668_50713"><p>No</p></td><td id="7dd75668_50714"><p>Not supported by HDP</p></td></tr><tr id="7dd75668_50715"><td id="7dd75668_50716"></td><td id="7dd75668_50717"><p>MariaDb</p></td><td id="7dd75668_50718"><p>10.1</p></td><td id="7dd75668_50719"><p>No, but should work as 10.2 does</p></td><td id="7dd75668_50720"></td></tr><tr id="7dd75668_50721"><td id="7dd75668_50722"></td><td id="7dd75668_50723"></td><td id="7dd75668_50724"><p>10.2</p></td><td id="7dd75668_50725"><p>Yes</p></td><td id="7dd75668_50726"></td></tr><tr id="7dd75668_50727"><td id="7dd75668_50728"></td><td id="7dd75668_50729"><p>Postgresql</p></td><td id="7dd75668_50730"><p>*</p></td><td id="7dd75668_50731"><p>NOT YET IMPLEMENTED</p></td><td id="7dd75668_50732"></td></tr><tr id="7dd75668_50733"><td id="7dd75668_50734"></td><td id="7dd75668_50735"><p>Oracle</p></td><td id="7dd75668_50736"><p>*</p></td><td id="7dd75668_50737"><p>NOT YET IMPLEMENTED</p></td><td id="7dd75668_50738"></td></tr><tr id="7dd75668_50739"><td id="7dd75668_50740"><p><code class="code" id="7dd75668_50741">sre</code></p></td><td id="7dd75668_50742"><p>MySql</p></td><td id="7dd75668_50743"><p>5.6</p></td><td id="7dd75668_50744"><p>Limited</p></td><td id="7dd75668_50745"><p>Recommend upgrading 5.7. This is the lower MySql supported env for HDP</p></td></tr><tr id="7dd75668_50746"><td id="7dd75668_50747"></td><td id="7dd75668_50748"></td><td id="7dd75668_50749"><p>5.7</p></td><td id="7dd75668_50750"><p>Partly</p></td><td id="7dd75668_50751"><p>Some <code class="code" id="7dd75668_50752">sre</code> reports use CTE in the SQL, which isn't supported in this version. Those report will error, the other will run fine.</p></td></tr><tr id="7dd75668_50753"><td id="7dd75668_50754"></td><td id="7dd75668_50755"></td><td id="7dd75668_50756"><p>8.0</p></td><td id="7dd75668_50757"><p>No</p></td><td id="7dd75668_50758"><p>Not supported by HDP</p></td></tr><tr id="7dd75668_50759"><td id="7dd75668_50760"></td><td id="7dd75668_50761"><p>MariaDb</p></td><td id="7dd75668_50762"><p>10.1</p></td><td id="7dd75668_50763"><p>No, but should work as 10.2 does</p></td><td id="7dd75668_50764"></td></tr><tr id="7dd75668_50765"><td id="7dd75668_50766"></td><td id="7dd75668_50767"></td><td id="7dd75668_50768"><p>10.2</p></td><td id="7dd75668_50769"><p>Yes</p></td><td id="7dd75668_50770"></td></tr><tr id="7dd75668_50771"><td id="7dd75668_50772"></td><td id="7dd75668_50773"><p>Postgresql</p></td><td id="7dd75668_50774"><p>9.6</p></td><td id="7dd75668_50775"><p>No, but should work</p></td><td id="7dd75668_50776"></td></tr><tr id="7dd75668_50777"><td id="7dd75668_50778"></td><td id="7dd75668_50779"></td><td id="7dd75668_50780"><p>10</p></td><td id="7dd75668_50781"><p>Yes</p></td><td id="7dd75668_50782"><p>Field Tested, May still be a few rough edges</p></td></tr><tr id="7dd75668_50783"><td id="7dd75668_50784"></td><td id="7dd75668_50785"></td><td id="7dd75668_50786"><p>11</p></td><td id="7dd75668_50787"><p>No, but should work at 10 does</p></td><td id="7dd75668_50788"></td></tr><tr id="7dd75668_50789"><td id="7dd75668_50790"></td><td id="7dd75668_50791"><p>Oracle</p></td><td id="7dd75668_50792"><p>12</p></td><td id="7dd75668_50793"><p>Yes</p></td><td id="7dd75668_50794"><p>Field Tested, May still be a few rough edges</p></td></tr></tbody ></table ></div><p id="7dd75668_50795">Ensure you have the database appropriate driver in the <code class="code" id="7dd75668_50796">${HOME}/.hive-sre/aux_libs</code> directory.</p><p id="7dd75668_50797">I've tried to match supported DB's for HDP 2.6.5 and 3.1.x as much as I could.</p></section><section class="chapter"><h2 id="hadoop-cli" data-toc="hadoop-cli">Hadoop CLI</h2><p id="7dd75668_50798">Running <code class="code" id="7dd75668_50799">hive-sre-cli</code> on the command line is an alias to the <code class="code" id="7dd75668_50800">hadoopcli</code> application <a href="https://github.com/dstreev/hadoop-cli" id="7dd75668_50801"   data-external="true" rel="noopener noreferrer" >here</a>.</p><p id="7dd75668_50802">It is an interactive HDFS Client Command Line tool.</p></section><section class="chapter"><h2 id="ping-performance-tool" data-toc="ping-performance-tool">Ping Performance Tool</h2><p id="7dd75668_50803">Included in this application suite is a <code class="code" id="7dd75668_50804">ping</code> performance tool that you can use to measure cluster host letancy. It is a MapReduce application that uses a list of hosts and will <code class="code" id="7dd75668_50805">ping</code> those hosts from the MR Map Task and record the results to HDFS.</p><p id="7dd75668_50806">The MR program take a few options:</p><div class="code-block" data-lang="none"         >
usage: hadoop jar &lt;jar-file&gt; com.cloudera.utils.mapreduce.MRPingTool -d &lt;output-dir&gt; -hl &lt;hdfs_host_list_file&gt; [-c &lt;count&gt;] [-m &lt;num_of_mappers&gt;]
 -c,--count &lt;arg&gt;        Ping Count (The number of iterations we'll run
                         ping).  Each ping request makes 5 pings.
                         So if this value is 3, we'll do 3 sets of 5 pings
                         (15 total). Default 5
 -d,--directory &lt;arg&gt;    Output Directory [REQUIRED]
 -h,--help               Help
 -hl,--host-list &lt;arg&gt;   The host list file on HDFS. A text file with a
                         FQHN (full qualified host name) per
                         line.[REQUIRED]
 -m,--mappers &lt;arg&gt;      Number of Mappers.  To get coverage, should be
                         more than the compute node count.  But no
                         guarantee of even distribution, so best to over
                         subscribe. Default 2
</div><section class="chapter"><h3 id="tested-os-s" data-toc="tested-os-s">Tested OS's</h3><p id="7dd75668_50808">CentOS 7.6 (ping)</p><p id="7dd75668_50809">The ping output is parsed by the application and other OS/versions may yield different output, which we've not (yet) setup parsing for.</p></section><section class="chapter"><h3 id="let-s-assume" data-toc="let-s-assume">Let's assume:</h3><ul class="list _ul" id="7dd75668_50810"    ><li class="list__item" id="7dd75668_50811"><p>You've downloaded the Hive <a href="https://github.com/cloudera-labs/hive-sre/tree/main/src/main/resources/ping" id="7dd75668_50812"   data-external="true" rel="noopener noreferrer" >setup/ingest/eval scripts</a></p></li><li class="list__item" id="7dd75668_50813"><p>This has been tested again CentOS 7.</p></li><li class="list__item" id="7dd75668_50814"><p>The user running the MR job has rights in each compute node to run <code class="code" id="7dd75668_50815">ping</code>.</p></li><li class="list__item" id="7dd75668_50816"><p>That <code class="code" id="7dd75668_50817">ping</code> is allowed on the network and not blocked between hosts.</p></li><li class="list__item" id="7dd75668_50818"><p>The MR Job is run with the right user credentials and from an Edgenode configured for the target cluster. </p><ul class="list _ul" id="7dd75668_50819"    ><li class="list__item" id="7dd75668_50820"><p>We need the hadoop MR libs to submit the job.</p></li></ul></li><li class="list__item" id="7dd75668_50821"><p>The user running the job has ACL's that allow them to write to the EXTERNAL db location you create with <code class="code" id="7dd75668_50822">ping_ddl.sql</code>.</p></li><li class="list__item" id="7dd75668_50823"><p>Build a 'host list' file with ALL the FQHN (fully qualified hostnames) in the cluster that you want to test. </p><ul class="list _ul" id="7dd75668_50824"    ><li class="list__item" id="7dd75668_50825"><p>This is a text file with a single host FQHN per line. Similar to /etc/hosts.</p></li><li class="list__item" id="7dd75668_50826"><p>Place the file (we'll use the name <code class="code" id="7dd75668_50827">host_list.txt</code>) in your HDFS home directory.</p></li></ul></li><li class="list__item" id="7dd75668_50828"><p>We are using the standard EXTERNAL and MANAGED Warehouse locations on HDFS</p></li><li class="list__item" id="7dd75668_50829"><p>PING_DB = ping_perf</p></li><li class="list__item" id="7dd75668_50830"><p>BATCH_ID = 2022-10-22_01</p></li></ul></section><section class="chapter"><h3 id="procedure" data-toc="procedure">Procedure</h3><ol class="list _decimal" id="7dd75668_50831"  type="1"  ><li class="list__item" id="7dd75668_50832"><p>Run DDL Scripts in Beeline </p><ol class="list _decimal" id="7dd75668_50833"  type="1"  start="2"><li class="list__item" id="7dd75668_50834"><p><code class="code" id="7dd75668_50835">beeline -f ping_ddl.sql --hivevar PING_DB=ping_perf</code></p></li></ol></li><li class="list__item" id="7dd75668_50836"><p>Run MR Job, using the expected Partition Directory of the <code class="code" id="7dd75668_50837">raw</code> table as the output. The <code class="code" id="7dd75668_50838">-m</code> parameter controls the number of 'mappers' created. The intent is to get a map task on every compute node in the cluster. To do that, with perfect distribution (unlikely), you need at least as many mappers as there are compute nodes. We recommend 2-3x that incase some nodes get doubled up. There's no way to ensure every host runs a task, hence the over subscription here. Use the eval report to determine where the gaps where (if any) and run again. </p><ol class="list _decimal" id="7dd75668_50839"  type="1"  start="4"><li class="list__item" id="7dd75668_50840"><p><code class="code" id="7dd75668_50841">hadoop jar /usr/local/hive-sre/lib/hive-sre-shaded.jar com.cloudera.utils.mapreduce.MRPingTool -m 40 -c 3 -hl host_list.txt -d /warehouse/tablespace/external/hive/ping_perf.db/raw/batch_id=2022-10-21_01</code></p></li></ol></li><li class="list__item" id="7dd75668_50842"><p>Run the Ingest script in <code class="code" id="7dd75668_50843">beeline</code></p><ol class="list _decimal" id="7dd75668_50844"  type="1"  start="6"><li class="list__item" id="7dd75668_50845"><p><code class="code" id="7dd75668_50846">beeline -f ping_ingest.sql --hivevar PING_DB=ping_perf --hivevar BATCH_ID=2022-10-21_01</code></p></li></ol></li><li class="list__item" id="7dd75668_50847"><p>Run the <a href="https://github.com/cloudera-labs/hive-sre/blob/main/src/main/resources/ping/ping_eval.sql" id="7dd75668_50848"   data-external="true" rel="noopener noreferrer" >eval scripts</a> in <code class="code" id="7dd75668_50849">beeline --hivevar PING_DB=ping_perf --hivevar BATCH_ID=2022-10-21_01</code></p></li></ol></section></section><div class="last-modified"> Last modified: 06 November 2023</div><div data-feedback-placeholder="true"></div><div class="navigation-links _bottom">   <a class="navigation-links__next" href="hive-sre-sub-commands.html">Sub-Commands</a>  </div></article><div id="disqus_thread"></div></div></section></main></div>  <script src="https://resources.jetbrains.com/writerside/apidoc/6.1.5-b176/app.js"></script></body></html>